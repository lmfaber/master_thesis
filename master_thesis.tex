\documentclass[12pt,a4paper,english]{article}
\usepackage[left=2cm, right=2cm, bottom=3cm, top=3cm]{geometry}
% scrartcl ist eine abgeleitete Artikel-Klasse im Koma-Skript
% zur Kontrolle des Umbruchs Klassenoption draft verwenden

\usepackage{xspace}

%% FIX THE TABLES
\usepackage{float}
\floatstyle{plaintop} % Force table captions top
\restylefloat{table}

% Landscape for tables in appendix
\usepackage{lscape}

% Beautifult tables
\usepackage{rotating, booktabs}

%% brueche schoen darstellen
\usepackage{textcomp}
\usepackage{xfrac}

%% Meta-Command for defining new species macros
\newcommand{\species}[3]{%
  \newcommand{#1}{\gdef#1{\textit{#3}\xspace}\textit{#2}\xspace}}

%% Defining new species
% The first argument is the name of the macro you will call in the document.
% The second argument is what is written the first time the macro is called
% The third argument is what is written every subsequent time the macro is called.

\species{\ecoli}{Escherichia coli}{E.~coli}
\species{\celegans}{Caenorhabditis elegans}{C.~elegans}

% Use this to make Courier the font for the tools
\newenvironment{myfont}{\fontfamily{pcr}\selectfont}{\par}
\DeclareTextFontCommand{\prgm}{\myfont}

\newcommand{\program}[2]{
	\newcommand{#1}{\prgm{#2}\xspace}
}
\program{\salmon}{Salmon}
\program{\spades}{rnaSPAdes}
\program{\cdhit}{cd-hit-est}
\program{\soap}{SOAPdenovo-Trans}
\program{\trinity}{Trinity}
\program{\mclust}{MeShClust}
\program{\mclusttwo}{MeShClust\textsuperscript{2}}
\program{\umap}{UMAP}
\program{\hdbscan}{HDBSCAN}
\program{\mcl}{MCL}
\program{\fastp}{fastp}
\program{\orp}{Oyster River Protocol}
\program{\karma}{karma}
\program{\detonate}{DETONATE}
\program{\transrate}{TransRate}
\program{\busco}{BUSCO}
\program{\rnaquast}{rnaQUAST}
\program{\transabyss}{Trans-ABySS}
\program{\snakemake}{Snakemake}
\program{\hisat}{HISAT2}
\program{\flux}{Flux Simulator}
\program{\grouper}{Grouper}
\program{\trim}{Trimmomatic}
\program{\rcorrector}{RCorrector}
\program{\orthofuse}{OrthoFuse}
\program{\orthofinder}{OrthoFinder}
\program{\shannon}{Shannon}
\program{\blast}{BLAST}
\program{\linclust}{Linclust}
\program{\kmergenie}{KmerGenie}
\program{\dbscan}{DBSCAN}
\program{\uclust}{UCLUST}
\program{\vsearch}{VSEARCH}
\program{\tsne}{t-SNE}
\program{\muscle}{MUSCLE}
\program{\jalview}{Jalview}
\program{\intervene}{Intervene}
\program{\gmap}{GMAP}
\program{\blastn}{BLASTN}


%Math functions
\usepackage{mathtools}
\usepackage{relsize}

% Pictures
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage[labelfont=bf,font=small]{caption}
\captionsetup{justification=justified,singlelinecheck=false}

\usepackage{wrapfig}

% Abstand obere Blattkante zur Kopfzeile ist 2.54cm - 15mm
\setlength{\topmargin}{-15mm}


% die folgenden Packete erlauben den Gebrauch von Umlauten und ß in der Latex Datei
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\addto{\captionsenglish}{\renewcommand{\bibname}{References}} %References instead of bibliography

% Abkürzungsverzeichnis
\usepackage[automake]{glossaries}
% Generate the glossary
\makeglossaries

\usepackage{hyperref}

% Citation
%\usepackage[round,comma]{natbib}
\usepackage[square, numbers]{natbib}

\usepackage[nottoc,numbib]{tocbibind} %To get the references in table of contents with numbers

% Dotted lines after sections
\usepackage[titles]{tocloft}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}

% Site layout
\usepackage{fancyhdr}
\fancyhf{}
% \fancyhead[R]{\nouppercase\leftmark}
\fancyhead[R]{\rightmark}
\fancyfoot[C]{\thepage}

% 
%\usepackage[pdftex]{graphicx}
%\usepackage{latexsym}
%\usepackage{amsmath,amssymb,amsthm}

% Make indentation of list of tables and figures = 0
\makeatletter
\renewcommand*\l@figure{\@dottedtocline{1}{0pt}{2.3em}}
\renewcommand*\l@table{\@dottedtocline{1}{0pt}{2.3em}}
\makeatother


%% LIST OF TABLES WITHOUT TITLE
\makeatletter
\renewcommand\listoftables{%
        \@starttoc{lot}%
}
\makeatother
%% LIST OF FIGURES WITHOUT TITLE
\makeatletter
\renewcommand\listoffigures{%
        \@starttoc{lof}%
}
\makeatother

\usepackage[onehalfspacing]{setspace}

\begin{document}

	% Keine Seitenzahlen im Vorspann
	\pagestyle{empty}
	% Titelblatt der Arbeit
	\begin{titlepage}
		\begin{center}
			\begin{figure}[H]
				\centering
				\includegraphics[width=0.6\textwidth]{images/Logo-Paket_Uni_Jena/Logo_Uni_Jena/Bild-Wort-Marke/jpg/UniJena_BildWortMarke_blue.jpg}
			\end{figure}
	
			\vspace*{2cm}
			\begin{Large}
				Combining k-mer and quasi-read-mapping\\
				methods to improve the clustering of\\
				multiple \textit{de novo} transcriptome assemblies\\
			\end{Large}

			\vspace{2cm}
			\begin{Large}
			\textbf{M~A~S~T~E~R~'~S~~~T~H~E~S~I~S}\\
			\end{Large}
			~\\
			to obtain the academic degree\\
			Master of Science (M. Sc.)\\
			in bioinformatics
			\vfill
			Friedrich Schiller University Jena\\
			Faculty of mathematics and computer science\\
			~\\
			submitted by Lasse Faber\\
			born on June 26 1992 in Karlsruhe\\
			~\\
			Supervisor: Prof. Dr. M. Marz\\
			Jena, \today
		\end{center}
	\end{titlepage}

%%%%%%%%%%%%%%%%
%%% Abstract %%%
%%%%%%%%%%%%%%%%
\newgeometry{left=4cm, right=2cm, bottom=3cm, top=3cm}

\section*{Abstract}
	Many \textit{de novo} transcriptome assemblers yield different results due to their distinct implementations. This master's thesis aims to use the advantages of several assemblers and create an improved \textit{de novo} transcriptome assembly. Concatenating multiple assemblies complicates the downstream analysis, such as annotation of the transcripts and the identification of differentially expressed isoforms. Here, a new algorithm based on \textbf{K}-mer \textbf{A}nd quasi-\textbf{R}ead-\textbf{MA}ppings (\karma) is implemented that can be used on paired-end and single-end RNA-Seq data. The method relies on recent k-mer and read-graph-based clustering methods that are combined and enhanced. \karma is compared to state-of-the-art clustering tools and evaluated in terms of completeness and correctness of the resulting \textit{de novo} transcriptome assembly.
	
	Conclusively, it seems sufficient to rely on a single assembler rather than combining multiple assemblers for the most use cases. However, preprocessing of reads, assembler choice and suitable k-mer size should be carefully considered. Clustering single-end datasets with \cdhit with a sequence identity of 90~\% show significant improvements for the assemblies.
	Even though \karma was not able to outperform other clustering methods, a comprehensive evaluation of the underlying algorithm is performed. The read-graphs built by \karma can be utilized for further investigations of reliable \textit{de novo} reconstructed isoforms from transcriptomic sequencing data.

\newpage
\section*{Zusammenfassung}
    Viele \textit{de novo} Transkriptom-Assemblierer produzieren aufgrund ihrer unter\-schied\-lichen Implementierungen verschiedene Ergebnisse. Ziel dieser Masterarbeit ist es, die Vorteile mehrerer Assemblierer zu nutzen, um eine verbesserte \textit{de novo} Transkriptom-Assemblierung zu erhalten. Die durch diese Methode entstehende Redundanz soll mittels eines eigens implementierten Algorithmus reduziert werden. Der Algorithmus (\karma, engl. \textbf{K}-mer \textbf{A}nd quasi-\textbf{R}ead-\textbf{MA}ppings) benutzt, kombiniert und verbessert bereits bestehende k-mer und Graphen-basierte Methoden.
    Die Methode eignet sich außerdem für Single-End und Paired-End Datensätze von RNA-Sequenzierungen.
    \karma wird mit aktuellen Clustering-Programmen verglichen und hinsichtlich der Vollständigkeit und Qualität der resultierenden \textit{de novo} Transkriptom-Assemblierung bewertet.
    
	Für die meisten Anwendungsfälle ist es ausreichend, einen einzigen Assemblierer zu verwenden. Allerdings sollte die Vorverarbeitung von Reads, die Wahl des Assemblierers und eine geeignete k-mer-Länge sorgfältig gewählt werden. Für Single-End-Datensätze erzielt \cdhit mit einer Sequenzidentität von 90~\% signifikante Verbesserungen für die Transkriptom-Assemblierung.
	Die von \karma erstellten Graphen können für weitere Untersuchungen von zuverlässig \textit{de novo} rekonstruierten Isoformen aus Transkriptomdaten verwendet werden.
	

%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Inhaltsverzeichnis %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\pagestyle{empty}
\tableofcontents

%%%%%%%%%%%%%%%%%%
%%% Einleitung %%%
%%%%%%%%%%%%%%%%%%
\newpage
\pagestyle{fancy}
\renewcommand{\sectionmark}[1]{\markright{#1}}
\section{Introduction}
    Understanding biological processes at the molecular level has always been of great interest to life science researchers.
    Being responsible for cellular mechanisms and responses, the transcriptome is a research topic of significant importance \citep{rnaseq:09}.
	The transcriptome represents all RNA molecules in a cell, reflecting its gene expression. Consequently, the methods for investigation of the transcriptome have made some remarkable changes over the past decade \citep{rev_rnaseq:17}. In the early days of molecular research, methods were time-consuming and restricted only to a small number of genes. The genes of interest were commonly chosen by hand, based on the function already known in other organisms \citep{Fitzpatrick:05}.
	This changed drastically with the appearance of microarrays that could be used to examine a large set of RNAs simultaneously, speeding up the research process \citep{Bhargava:13, Tarca:06}. With the rise of Next-Generation Sequencing methods such as provided by Illumina, transcriptome analysis became possible on an unprecedented scale and affordable for many research groups.
	Nowadays, it is possible to get information about the whole transcriptome of an entire organism in a cheap and comprehensive way by sequencing the RNA (RNA-Seq). In particular, RNA-Seq data can also provide information about new organisms where there has no genome been sequenced yet.
	
	\subsection{RNA-Sequencing data}
	\begin{wrapfigure}{R}{0.6\textwidth}
		\centering
		\def\svgwidth{0.6\textwidth}
		\vspace{-20pt}
		\input{images/01_intro/rna_seq.pdf_tex}
		\captionsetup{width=.95\linewidth}
		\caption[Search results for `RNA-Seq' on Pubmed over the years.]{Search results for `RNA-Seq' on Pubmed over the years \citep{growth}.}
		\label{img:growth}
	\end{wrapfigure}

    Since the design of microarrays relies on already known genes, RNA-Seq is superior for less-studied species lacking an appropriate reference genome \citep{rnaseq:09}. But RNA-Seq has even more advantages compared to microarrays. Over time it is becoming more and more cost-effective, has a higher sensitivity and accuracy and allows for the detection of new transcripts, including non-coding RNA (ncRNA) \citep{Rodriguez-Garcia:17}.
	The inclusion of RNA-Seq data is now part of the standard repertoire in many studies (Figure~\ref{img:growth}). For example, \citeauthor{Wang:19} have used RNA-Seq data for ovarian cancer research \citep{Wang:19}. Their findings lead to earlier detection and identification of the pathological origin by determining the responsible genes hence dysregulated molecular pathways \citep{Wang:19}.
	Furthermore, \citeauthor{Rai:18} describe the supremacy of RNA-Seq data analysis over microarrays in their studies of profiling human ligament tissue \citep{Rai:18}.
	With all the advantages from above, the number of publications that use RNA-Seq data for their analyses has been steadily growing over the past few years (Figure~\ref{img:growth}). Along with the increase of publications comes a large number of freely available RNA-Seq datasets in the NCBI Sequence Read Archive (SRA) and EMBL-EBI European Nucleotide Archive (ENA).


\subsection{Transcriptome reconstruction}
    Besides the use for differential gene expression analyses, RNA-Seq data can also be applied to assemble the transcripts of the whole transcriptome.
    This includes all different forms of expressed genes, hence the transcription from the genomic DNA into RNA molecules. These can be categorized either as non-coding RNA or protein-coding RNA. The latter is further processed and translated into a protein that fulfills a certain function in the cell. However, before the translation into a protein, the protein-coding RNA can be altered through post-transcriptional modifications such as alternative splicing. The resulting distinct variants of the same gene represent different isoforms \citep{splicing:03}. Contrarily, a non-coding RNA is not translated into a protein, but functions as it is \citep{ncRNA:05}.
    
    The widely used Illumina sequencing protocols all rely on fragmentation steps, thus produce reads of lengths between approximately 100-350~base pairs (bp). Consequently, the shorter reads have to be combined (\textit{assembled}) to reconstruct the original transcript sequences. The final transcripts are also called contiguous sequences (\textit{contigs}). However, assembling the reads in a way that they represent their original biological state comes with a few challenges to solve, such as the orientation of reads, repeats, contamination, sequencing errors and chimeras \citep{rev_rnaseq_problems:11}.
    
    Additionally, an assembly can be done either with a reference genome or without \citep{transcriptome_misassemblies:11}. Reconstruction, while having no reference available, is called a \textit{de novo} assembly and makes the task more difficult since there is no previous knowledge about the order of the reads.
    The general aim of a (\textit{de novo}) transcriptome assembly should be complete in isoforms \citep{transcriptome_isoforms:18}, have low redundancy \citep{transcriptome_redundancy:15} and as few misassembled transcripts as possible \citep{transcriptome_misassemblies:11}. 
    
    Fortunately, there are a lot of tools that are already dealing with the transcriptome assembly problem such as \soap \citep{SOAPdenovo-Trans:14}, \trinity \citep{Trinity:11}, \transabyss \citep{Trans-ABySS:10} and \spades \citep{rnaSPAdes:18}. However, all these tools have different advantages and disadvantages also depending on the input data set \citep{hoelzer:19}. All those programs are based on k-mer dependent De Bruijn graphs, where the reads are divided into subsequences of length $k$ during the assembly process \citep{rev_bruijn:11}. The selection of the correct k-mer size can be a challenge itself. Whereas small k-mer sizes tend to recover less abundant transcripts, they produce a lot of contigs that suffer from fragmentation due to lack of overlap and sequencing errors. On the other hand, big k-mer sizes have the advantage of producing a more connected assembly that consists of high coverage transcripts and spliced variants. Yet, the assembly contains fewer contigs, which leads to a lower transcript representation \citep{Rana:16}. There are existing tools that try to estimate the best available k-mer size, such as \kmergenie \citep{kmerGenie:13}. The developers of the program also conclude that combining assemblies from a small and big k-mer size can be beneficial \citep{kmerGenie:13}, nowadays a common procedure implemented in assembly tools such as \spades \citep{rnaSPAdes:18}.
    
    Despite being based on De Bruijn graphs, all of the assemblers likely yield different assemblies due to the distinct implementations and assumptions of their developers. \citeauthor{OysterRiverProtocol:18} implemented the \orp \citep{OysterRiverProtocol:18} to combine multiple assemblies to receive an overall better assembly. The assumption here is that the combination of multiple assemblies will negate weaknesses from single assemblers and results in a better overall assembly. Even though more information from multiple assemblers is gained \citep{hoelzer:19}, a lot of redundancy is introduced that has to be taken care of through clustering.
    This master's thesis takes up this idea and deals more deeply with the problem of transcript clustering.
    Since many clusterings and their underlying methods are based on the concept of graphs, the following section will give a brief introduction into the topic.
	
\subsection{Basic graph theory}    	
    In short, a graph is a data structure to represent a relationship between objects. The formal description of a graph is $ G = (V, E, \omega) $, where a set of objects represent the vertices $V$ and their relationship among them as edges $E$.
	A distance based on a function $\omega$ can be assigned to the edges to show a (dis-) similarity between different vertices. This value is also called the weight of an edge but is not a necessary property for a graph. Without the weights, the graph is called an \textit{unweighted graph} (Figure~\ref{img:graphs}A) or with weights a \textit{weighted graph} (Figure~\ref{img:graphs}B), respectively.
	\begin{figure}[h]
		\centering
		\def\svgwidth{\textwidth}
		\input{images/01_intro/graphs.pdf_tex}
		\caption[Visualization of different graphs.]{Visualization of different graphs. \textbf{(A)} A directed unweighted graph. \textbf{(B)}~An undirected weighted graph with weights between 0.1 and 0.9.}
		\label{img:graphs}
	\end{figure}
	Furthermore, the graph can be either \textit{directed} or \textit{undirected}. Assuming a walk through the graph between vertices using the edges as connections, directed edges only allow for a walk in one direction between two vertices (Figure~\ref{img:graphs}A). In an undirected graph, both directions are allowed (Figure~\ref{img:graphs}B) \citep{graph-theory:13}.
    The representation mentioned above of objects and their similarities offer one possibility to cluster objects.

\subsection{Clustering}
	\label{ss:clustering}
    \begin{wrapfigure}[15]{R}{0.5\textwidth}
	\centering
	\def\svgwidth{0.5\textwidth}
	\vspace{-37pt}
	\input{images/01_intro/base.pdf_tex}
	\captionsetup{width=.95\linewidth}
	\caption[Graphical example of objects in a two-dimensional feature space.]{Graphical example of objects in a two-dimensional feature space. Different colored dots represent groups of objects with distinct distributions.}.
	\label{img:base_cluster}
	\vspace{-20pt}
	\end{wrapfigure}
    Simply said, clustering describes the process of grouping a certain dataset into subsets of similar properties. 
	It is a problem that is not only bound to data science or bioinformatics but affects us every day e.g., while sorting laundry.
	The objects in the datasets usually have a vector of properties, which is a list of features for the data point. This can be seen as a simple representation of a multi-dimensional feature space (Figure~\ref{img:base_cluster}).
	
	In science, clustering is generally a classification problem.
	There are two main categories of classifications, unsupervised and supervised. When speaking of the latter, there is an existing set of examples based on which the classification task tries to classify new objects into existing labels.
	Contrarily, unsupervised classification tries to identify unknown patterns in a dataset without having pre-existing labels available.
	Therefore, clustering is unsupervised learning, where the resulting groups are based on some similarity among those objects \citep{cl_technique:17}. 
	The resulting subsets from the process are also called clusters.
	For the clustering task, there are already a vast number of implemented algorithms that can be categorized in at least one of the following four groups.
	
\subsubsection*{Hierarchical-based clustering (Connectivity-based clustering)}
	The hierarchical clustering is mainly based on the distance between objects, which represents a hierarchy (Figure~\ref{img:hierarchical}). The core idea is that objects are more related to objects closer to them than those further away.
	From the resulting hierarchy, there are two methods to extract the clusters. The bottom-up approach (agglomerative) starts with each object in its own cluster. Going up the hierarchy, the objects are then merged into clusters.
	The top-down approach (divisive) starts with all objects in one cluster. Going down the hierarchy, the first cluster is subsequently divided into smaller sub-clusters \citep{hierarchical:09}.
	
	\begin{figure}[H]
		\centering
		\def\svgwidth{\textwidth}
		\vspace{-15pt}
		\input{images/01_intro/hierarchy_combine.pdf_tex}
		\caption[Hierarchical-based clustering using the single-linkage method.]{Hierarchical-based clustering using the single-linkage method. The distance between the objects is calculated as Euclidean distance. Clusters are created with a threshold of 0.1 (red dashed line). \textbf{(A)}~Representation of the hierarchy as a dendrogram with Euclidean distance. \textbf{(B)}~The resulting clusters. Black dots represent single unclustered objects.}
		\label{img:hierarchical}
	\end{figure}

	In order to compare the similarity of clusters, the linkage criterion has to be chosen, such as single-linkage clustering (closest objects of two clusters), complete-linkage clustering (farthest away objects) or average-linkage clustering \citep{linkage_criterion:13}. This is necessary, since a cluster may contain more than one object, and there has to be one candidate per cluster to calculate the distance from.
	Rather than providing one solution for the clustering problem, this method can provide different clusters based on the chosen distance.
	\newpage
		
\subsubsection*{Centroid-based clustering (Partitioning-based clustering)}
    Generally speaking, this method sets initial cluster centers (centroids) and shifts them iteratively until no further change is observed.
	One of the most well-known algorithms in this category is the k-means algorithm.
	The centroids are selected randomly and all other objects are assigned to the closest centroid sequence (Figure~\ref{img:centroid}A). The cluster centers are then updated to be the mean of all objects in the cluster. These two steps are repeated until the clusters don't change anymore (Figure~\ref{img:centroid}B) \citep{k-means:01}. Usually, the Euclidean, Minkowski or Manhattan metrics are used for distance computation. During the shifting process, objects also may change their clusters.
	This method suffers from the disadvantage that it requires the number of clusters in advance and is also sensitive to the initial centroid \citep{centroid:14}.
	
   	\begin{figure}[H]
		\centering
		\vspace{-10pt}
		\def\svgwidth{\textwidth}
		\input{images/01_intro/partitioning_comb.pdf_tex}
		\caption[Centroid-based clustering using the k-means algorithm.]{Centroid-based clustering using the k-means algorithm. The number of clusters is set to three. \textbf{(A)}~The centroids (red cross) are initialized randomly. \textbf{(B)}~After five iterations the shifting converges and builds the final clusters.}
		\label{img:centroid}
	\end{figure}

\subsubsection*{Distribution-based clustering}
    For this method, a probability model is used to assign the objects to clusters. Those probabilistic models usually have some parameters, which initially have to be guessed to represent the data (Figure~\ref{img:distribution}A). Afterwards, the cluster probabilities can be calculated for each object, allowing for a re-estimation of the probability parameters. This is performed iteratively until the parameters converge (Figure~\ref{img:distribution}B). 
    	\begin{figure}[H]
    	\centering
		\vspace{-10pt}
    	\def\svgwidth{\textwidth}
    	\input{images/01_intro/distribution.pdf_tex}
    	\caption[Distribution-based clustering using a Gaussian mixture model.]{Distribution-based clustering using a Gaussian mixture model. The distribution parameters are initialized randomly and the number of components is set to three. \textbf{(A)}~Random initialization of parameters of the distribution. \textbf{(B)}~Convergence after 17 iterations forming the final clusters.}
    	\label{img:distribution}
    \end{figure}
	Each object is then assigned to its respective cluster based on the probability it belongs to a certain distribution in the underlying data.
	The biggest drawback of this method is that it is computationally intensive and may be over-fitting the data \citep{distribution-based:04}. Furthermore, the assumption of the distribution has to fit the data, which is not likely known a priori \citep{distribution-based:03}. One representative for this method are Gaussian mixture models using the expectation-maximization algorithm (Figure~\ref{img:distribution}) \citep{distribution-based:ex-max:09}.

\subsubsection*{Density-based clustering}
   	\begin{wrapfigure}[22]{R}{0.5\textwidth}
   		\vspace*{-23pt}
		\centering
		\def\svgwidth{0.5\textwidth}
		\input{images/01_intro/density.pdf_tex}
		\captionsetup{width=.95\linewidth}
		\caption[Density-based clustering using \dbscan.]{Density-based clustering using \dbscan \citep{dbscan:96}. The radius is set to 0.07 and the number of samples in a neighborhood set to ten. A core object (red circle) has at least ten other object within its radius. Density-reachable objects (red dashed circle) have fewer objects in their circle, but are in a core objects reachability. Objects that do not have either of these properties are referred to as noise (red dotted circle). The result of the clustering are two clusters (blue and green) and a lot of unclustered objects (black points).}
		\label{img:density}
	\end{wrapfigure}
    Other than the distribution-based clustering, the density-based is a non-parametric approach. The reachability between objects plays a major role in this method (Figure~\ref{img:density}).
	Given an initial core object of the data and a radius $r$, there is a certain number of other objects that are within this radius. Those objects are also called directly density-reachable. 

	Only if there are more than $n$ neighbors within this radius, the object is considered a high-density area and is extended as follows. For each of the directly density-reachable neighbors, the same radius is used to identify new neighbor density-reachable objects. 
	The new object is only considered as a part of the cluster, if it has again at least $n$ directly density-reachable objects.
	It may be the case that new objects don't lie within the direct density-reachability of the core object. However, they can be reached through a neighbor by neighbor connection, which is called a density-reachable connection. 

	The search for new objects is repeated until no new object fulfills the requirement of minimum objects within the radius.
	Finally, a cluster is defined by all groups of density-reachable objects of the data \citep{density-based:05}.
	Objects that are not part of density areas, thus have not enough directly density-reachable objects, are considered noise.
	An advantage of this method is that the number of clusters doesn't have to be specified and the clusters may be arbitrarily shaped in the dimension space \citep{density-based:11}.
	Two of the most common algorithms implementing this approach are the \dbscan \citep{dbscan:96} and the mean-shift algorithm \citep{mean-shift:95}.\\
	\\
	\noindent
    Additionally, one can differentiate between hard and soft clustering. Hard clustering describes that each object has a cluster it belongs to or not, e.g. centroid-based clustering. In soft clustering, also called fuzzy clustering, each object can belong to more than one cluster, e.g., distribution-based clustering. Each element is a member of a cluster with a certain probability \citep{hard-vs-soft:14}.


	\subsection{Clustering in bioinformatics}
	The problem of clustering biological sequences is probably as old as bioinformatics itself. For example, already in the year 2007, it was aspired to remove redundant sequences from the Uniprot database to speed up the search of sequences in their database \citep{uniref:07}. However, with the rise of Next-Generation Sequencing, it becomes more and more relevant to handle the massively produced data.
	
	Over the last years, there have been various attempts for clustering biological sequences, such as \cdhit \citep{cd-hit:06, cd-hit:12}, \uclust \citep{uclust:10}, \linclust \citep{linclust:18} or \mclust \citep{meshclust:18}. Based on their application and the input data, all of these tools have their advantages and disadvantages, however their performance on clustering (\textit{de novo}) transcriptome assemblies remains particularly unknown.
	As mentioned above, the similarity of objects has to be compared to each other. For biological sequences, current clustering tools use different methods to calculate the sequence similarity, thus showing some kind of relationship between them.
	\cdhit, for example, compares sequences by calculating sequence alignments \citep{cd-hit:12}.
	Another approach is the extraction of k-mer profiles as properties for sequences and performing the clustering based on this information, which was recently performed for metagenomic binning \citep{binning:16}.
	In comparison, \mclust calculates similarities using alignment-free k-mer statistics such as length difference, Czekanowski similarity or Manhattan distance \citep{meshclust:18}.
	Unlike the general purpose of clustering sequences, recent research also focuses on clustering \textit{de novo} transcriptome assemblies, such as \grouper \citep{Grouper:18} and the \orp.
	As mentioned above, the \orp uses multiple transcriptome assemblies to enhance the resulting assembly regarding the completeness. Consequently, the tool implements a custom clustering algorithm.
	Contrarily, \grouper presents a method to improve a single transcriptome assembly utilizing the reads from which the assembly was created.
	
	\citeauthor{comprehensive-clustering:15} compare different clustering algorithms, but without biological context \citep{comprehensive-clustering:15}.
	\citeauthor{clustering_review:18} compares five different tools for the task of clustering a metagenomic sequencing to identify operational taxonomic units \citep{clustering_review:18}. Despite all of the various clustering methods and the general interest for (\textit{de novo}) transcriptome assemblies, a comprehensive study on clustering methods for \textit{de novo} transcriptome assemblies is missing. The topic of clustering remains a current problem in bioinformatics, especially for metagenomics and (\textit{de novo}) transcriptome assemblies.\\
	
	\noindent
	In this master's thesis, multiple assemblers are used to improve the completeness of the final assembly. A new algorithm for sequence clustering is implemented to remove the redundancy from the multiple assemblers. To overcome the clustering problem, recent k-mer and read-graph-based methods are combined and enhanced. The proposed method also offers the possibility to extract representative sequences for each cluster. Furthermore, the method is compared to state-of-the-art clustering tools and evaluated in terms of completeness and correctness of the resulting assembly.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% Material und Methoden %%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Material and Methods}
	All parameters are used as described. If not mentioned otherwise, the corresponding version's default parameters were used.

\subsection{Datasets}
\subsubsection*{Reads}
	The different clustering methods were tested on short-read Illumina datasets for \ecoli and \celegans. Four datasets with single- and paired-end library layouts were obtained from the European Nucleotide Archive while another one artificially created (Table~\ref{table:data}).
	
	\begin{table}[H]
		\caption[Datasets used in this master's thesis.]{Datasets used in this master's thesis. All analyses performed are based on these datasets. Paired-end data: PE. Single-end data: SE.}
		\label{table:data}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{lllllll}
				\toprule
				\textbf{\begin{tabular}[c]{@{}l@{}}Study\\ accession\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Run\\ accession\end{tabular}} & \textbf{Sequencer} & \textbf{Species} & \textbf{\begin{tabular}[c]{@{}l@{}}Library\\ layout\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Number\\ of reads\\ (million)\end{tabular}} & \textbf{\begin{tabular}[c]{@{}l@{}}Average\\ read\\ length\end{tabular}} \\ \addlinespace
				
				\midrule
				PRJNA383382 & SRR5456164 & \begin{tabular}[c]{@{}l@{}}Illumina\\ HiSeq 4000\end{tabular} & \celegans & PE & 29.1 & 100 \\ \addlinespace
				PRJEB29657 & ERR2886543 & \begin{tabular}[c]{@{}l@{}}Illumina\\ HiSeq 2000\end{tabular} & \celegans & SE & 22.5 & 51 \\ \addlinespace
				PRJEB8751 & ERR779269 & \begin{tabular}[c]{@{}l@{}}Illumina\\ HiSeq 2500\end{tabular} & \ecoli & PE & 16.4 & 100 \\ \addlinespace
				PRJNA343424 & SRR4255368 & \begin{tabular}[c]{@{}l@{}}Illumina\\ HiSeq 2000\end{tabular} & \ecoli & SE & 12.1 & 49 \\ \addlinespace
				- & CEL\_FLUX & \begin{tabular}[c]{@{}l@{}}Simulated\\ dataset\end{tabular} & \celegans & PE & 1.0 & 100 \\ \addlinespace
				\bottomrule
			\end{tabular}%
		}
	\end{table}

\subsubsection*{Reference datasets}
	To evaluate the datasets with the programs from Section~\ref{ssec:evaluation} the corresponding reference files for \ecoli (ASM584, v2; from NCBI) and \celegans (WBCel235, v96; from Ensembl) were used.

\newpage
\subsubsection*{Simulated dataset}
	\label{ssec:simulation}
	\begin{wraptable}{R}{7cm}
		\centering
		\caption[Input distribution for \flux.]{Input information for \flux. Distribution of all genes of the first chromosome of \celegans.}
		\label{table:input_flux}
		\begin{tabular}{lcc}
			\toprule
			 & \multicolumn{1}{r}{\textbf{Genes}} & \multicolumn{1}{r}{\textbf{Isoforms}} \\ \addlinespace
			\midrule
			total & 4046 & 6255 \\ \addlinespace
			protein-coding & 2908 & 5055 \\ \addlinespace
			ncRNA & 809 & 811 \\ \addlinespace
			antisense~RNA & 14 & 15 \\ \addlinespace
			lincRNA & 23 & 23 \\ \addlinespace
			rRNA & 5 & 5 \\ \addlinespace
			miRNA & 33 & 92 \\ \addlinespace
			snoRNA & 74 & 74 \\ \addlinespace
			piRNA & 98 & 98 \\ \addlinespace
			tRNA & 66 & 66 \\ \addlinespace
			snRNA & 16 & 16 \\ \addlinespace
			\bottomrule
		\end{tabular}
	\end{wraptable}
	The artificial dataset was created using the protein-coding and non-coding information of the first chromosome of \celegans. The distribution between the different types of RNA is listed in Table~\ref{table:input_flux}. A total of 1,000,000 paired-end reads with a length of 100~bases were created using \flux (Version 1.2.1) \citep{flux-simulator}. \flux is a tool that simulates the technical processes, such as reverse transcription, fragmentation, adapter ligation, PCR amplification as well as the sequencing to create FASTQ files. For each step a model based on real sequencing data is used, ensuring that the artificial reads have the same features and problems as real reads. The complete parameters and models used can be found in the \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/flux_simulator}{supplemental data} (See Section~\ref{appendix:supplements}). Note that the \mbox{miRNAs} include pre-miRNAs, which are represented as isoforms in Table~\ref{table:input_flux}. Furthermore, the existing isoforms of \mbox{miRNAs}, \mbox{ncRNAs} and antisense~RNAs usually only differ a few nucleotides, but are listed as single isoforms in the annotation files.

\subsection{\textit{De novo} transcriptome assemblies}
	\label{ssec:assemblies}
	The tool \fastp (Version 0.20) was used to take care of all necessary preprocessing steps \citep{fastp:18}. \fastp is an ultra-fast all-in-one FASTQ preprocessor. The default settings were used to perform a quality filter (Phred~score~>~15), length filter (Reads~>~15~bp) and adapter trimming (automatic detection). The parameter \texttt{-{}-low\_complexity\_filter} (30~\%) was enabled to remove low complexity, defined as the percentage of bases that differ from the following base. For paired-end reads, the option \texttt{-c} was used for base correction. Additionally, the parameter \texttt{-{}-detect\_adapter\_for\_pe} was enabled to automatically detect adapter sequences for paired-end data.\\
	
	\noindent
	Three different programs were used to perform the \textit{de novo} transcriptome assemblies. The assemblers \spades \citep{rnaSPAdes:18}, \soap \citep{SOAPdenovo-Trans:14} and \trinity \citep{Trinity:11} were chosen, because they performed comparatively well in a recent studies \citep{hoelzer:19}.
	
	\spades (Version 3.13.1) was used with default settings. By default, the tool incorporates two different k-mer sizes into the assembly process. 
	The k-mer size is based on the average read length. The upper k-mer size is approximately \sfrac{1}{2} of the read length and the lower approximately \sfrac{1}{3} of the read length.
	
	Since \soap (Version 1.04) doesn't perform multiple k-mer assemblies by default, the tool was started with two different k-mers. The k-mer sizes are roughly \sfrac{1}{2} and \sfrac{2}{3} of the input read length. Finally, the two assemblies were merged using \cdhit (Version 4.8.1) \citep{cd-hit:06,cd-hit:12} with a sequence identity of 100~\% creating the final \soap assembly.
	
	\trinity (Version 2.8.4) was also used with default settings. The tool is subdivided into three parts: Inchworm, Chrysalis and Butterfly. Utilizing greedy k-mer based assembly (k = 25), Inchworm produces unique sequences of transcripts, representing a set of alternative variants with shared k-mers.
	Chrysalis then forms clusters from those contigs that are overlapping and builds a separate De Bruijn graph for each cluster.
	Subsequently, Butterfly traces the routes that reads can take through the graph and reports all trustworthy transcript sequences, representing alternatively splices isoforms.\\
	
	\noindent
	The three final assemblies from \spades, \soap and \trinity, were then concatenated into one file and served as a basis for the following clustering methods. All steps mentioned in this section were combined in one pipeline using \snakemake \citep{Snakemake:12} and can be found on \href{https://github.com/lmfaber/multi_assembly}{GitHub} (See Section~\ref{appendix:pipelines}).

\subsection{Clustering tools}
    All clustering methods were combined in a \snakemake pipeline as well, which are accessible via \href{https://github.com/lmfaber/clustering}{GitHub} (See Section~\ref{appendix:pipelines}).
	
\subsubsection*{cd-hit-est}
	\cdhit (Version 4.8.1) \citep{cd-hit:06, cd-hit:12} performs clustering based on sequence similarity. The program uses a short word filter to reduce the number of alignments that have to be calculated for sequence similarity. In brief, this relies on the idea that two sequences with a certain similarity percentage also share certain counts of different k-mers. Therefore, if those conditions are not satisfied, no alignment has to be computed \citep{cd-hit:01}.
	
	The similarity of clustered sequences can be set with the parameter \texttt{-c}. Two different runs with two settings of sequence similarity were performed. One approach was quite strict with a sequence similarity of 100~\% (c~=~1) while the other one was less stringent with a similarity of 90~\% (c~=~0.9).

\subsubsection*{Oyster River Protocol}
	The \orp (Version 2.2.6) \citep{OysterRiverProtocol:18} is a pipeline that also has the aim of combining the strengths of different assemblers to generate a better overall assembly.
	
	The \orp removes Illumina sequencing adapters and trims the reads with \trim \citep{Trimmomatic:14}. Subsequently, they are error corrected using \rcorrector \citep{RCorrector:15}.
	\citeauthor{OysterRiverProtocol:18} is using three assemblers \citep{OysterRiverProtocol:18}. \trinity was used with default settings (k~=~25) and without read normalization. For \spades, two different k-mer sizes were used (k~=~55/75) in two distinct runs. Other than described in their paper and also mentioned on their website, the assembler \shannon \citep{Shannon:16} was replaced by \transabyss \citep{Trans-ABySS:10} and used with a k-mer size of 32. Those four assemblies are then merged using the following description.
	
	The merging process is performed using \orthofuse. First, all transcripts are concatenated and then sorted into groups of homologous transcripts using a modified version of \orthofinder \citep{OrthoFinder:15}, which accepts nucleotide sequences. The protocol then makes use of \transrate{s} \cite{TransRate:16} contig scores. For each homologous group, only the best contig (highest contig score) is accepted for the final assembly.
	Because the \orp uses \transrate for their merging process, the pipeline is restricted to paired-end data only. The contig score from \transrate is, among other things, dependent on information coming from read pairs, making its calculation only possible for paired-end data.
	
	We used the paired-end reads preprocessed with \fastp (Section~\ref{ssec:assemblies}) as input for this pipeline in all of the paired-end datasets. Since the \fastp preprocessing was chosen to be not very restrictive, only a few reads get filtered out, similar to the quality filtering directly performed by the \orp.

\subsubsection*{Linclust}
	The algorithm implemented in \linclust \citep{linclust:18} can reduce the number of pairwise sequence comparisons drastically. Sequences with similar k-mers are grouped and the longest sequence is set as the center of the group. 
	Each sequence is then compared only with each representative sequence with which it shares a k-mer, and not with all other sequences that it shares a k-mer. For this reason, the runtime scales linear with the size of the input set of sequences and is independent of the number of clusters.
	The sequence identity scores are then formed into a graph and trimmed with an identity threshold. The representative sequence is selected via greedy incremental clustering, which will almost always yield the longest sequence as a result.

	Originally implemented only for protein sequences, an option for nucleotide sequences was added later. \linclust (Version 10.6d92c) was used with default parameters according to the manual available in the corresponding \href{https://github.com/soedinglab/mmseqs2/wiki#linclust}{GitHub repository}.

\subsubsection*{Grouper}
    \grouper \citep{Grouper:18} is a program that is specifically designed to cluster \textit{de novo} transcriptome assemblies for further downstream analyses. The tool is based on the equivalence classes provided by \salmon \citep{salmon:17}, which gives information about how many reads are shared between contigs. With this information, a weighted undirected graph is constructed, representing contigs as nodes. The weight of the edges is based on the number of shared reads between contigs compared to the amount of individually mapped reads. The graph is then clustered using \mcl \citep{mcl:00}.

	If provided with a reference genome of a related species, \grouper will also use annotations to improve the clustering. Since, in this master's thesis, no clustering method used information from related species, this option was not used to allow a fair comparison.
	For the quasi-mapping with \salmon, duplicate transcripts were kept while indexing using the parameter \texttt{-{}-keepDuplicates}. The mappings were validated with \texttt{-{}-validateMappings} and orphan reads were allowed though \texttt{-{}-allowOrphans}. To create the equivalence class the option \texttt{-{}-dumpEq} was passed.
	\grouper (Version 0.1.1) was then started two different times with the parameters \texttt{orphan} and \texttt{mincut} set both to true or false. If those flags are enabled, \citeauthor{Grouper:18} state that \grouper may produce better results in case of a lower quality assembly \citep{Grouper:18}.
	
	Despite clustering, the tool does not select a representative sequence per cluster. To overcome this limitation, the longest sequence was chosen as representative, similar to \cdhit.

\subsubsection*{MeShClust}
    Most of the tools available for clustering nowadays are working with greedy algorithms, e.g. \cdhit. For those tools, the user must provide a sequence similarity score to define how similar sequences should be to be grouped into one cluster. \citeauthor{meshclust:18} describe \mclust as an intelligent tool for clustering DNA, which is independent of the user input \citep{meshclust:18}. It utilizes an unsupervised machine learning algorithm, respectively, called the mean shift algorithm.
	In brief, the input sequences are sorted based on their length. The shortest sequence is then picked as a center sequence. Based on this sequence, further similar sequences are detected. Similar sequences are selected using a General Linear Model (GLM) that was trained on the original data using alignment-free measures such as sequence length difference, Pearson coefficient, etc. After that, the mean shift is applied and the sequence closest to the mean is set as the new center sequence. This process is repeated until no new sequences join the cluster. In the next iteration, the shortest sequence is taken again as a new cluster start and the process is repeated until no sequences are left.

	\mclust (Version 1.2.0) was used with default parameters and the representative sequences were extracted from the resulting cluster file.

\subsubsection*{MeShClust\textsuperscript{2}}
	\mclusttwo \citep{meshclust2:18} is the successor of \mclust. As \citeauthor{meshclust:18} state in their paper, \mclust is optimized for sequences with sequence identity above 60~\% and is not scalable to longer sequences \citep{meshclust:18}. To solve these problems \mclusttwo was developed. \mclusttwo (Version 2.3.0) was also used with default parameters.

\subsubsection*{karma}
	\label{sssec:karma}
	\karma (\textbf{K}-mer \textbf{A}nd quasi-\textbf{R}ead-\textbf{MA}pping based clustering) is the working name of the program developed during this master's thesis. It combines a k-mer based clustering with a read-graph-based method, similar to \grouper. Figure~\ref{img:karma_workflow} shows the general workflow of \karma.
	
	As seen in Figure~\ref{img:karma_workflow}A1, the pipeline starts with a k-mer based clustering. A k-mer profile for each sequence is generated, resulting in a high dimensional space matrix. The k-mer frequency is then normalized to the sequence length. Initially, the k-mer size was adapted from \citeauthor{binning:16} that performed a successful metagenomic binning \citep{binning:16}. In their study, the authors tested different k-mer sizes along with a 5p6-mer, which is a combination of 5-mers and palindromic 6-mers. 
	The results using 5p6-mers are comparatively superior if more than 50 clusters are generated \citep{binning:16}.
	Considering the target of this tool, where each cluster will represent a gene with its isoforms, the threshold of 50 clusters will be exceeded. For example, \ecoli has more than 3000 expressed genes during exponential growth, not accounting for non-protein-coding transcripts \citep{ecoli:99}.
	
	The huge dimensional matrix contains a lot of information, not all of which is necessary to perform successful clustering. For this reason, the information is usually reduced to features that are relevant throughout all sequences. The Barnes-Hut implementation of \tsne from \citeauthor{binning:16} \citep{binning:16}, until recently commonly used to cluster single-cell RNA-Seq data \citep{tSNE_common:19}, was replaced by `Uniform Manifold Approximation and Projection for Dimension Reduction' (\umap) \citep{umap:18}.
	
	\subsubsection*{UMAP}
	Just like \tsne, \umap is a k-neighbor graph-based algorithm, which can be divided into two steps for a quick summary of the algorithm. The first step is the graph construction.
	For each input data point, the set of the k-nearest neighbors are calculated utilizing the nearest neighbor descent algorithm \citep{k-near:11}, resulting in fuzzy simplicial sets.
	Afterwards, the weights between all members of those sets are calculated using a weighting function so that the adjacency matrix is symmetric. The result is an undirected weighted graph.
	In the second step, the actual dimension reduction is performed using a force-directed graph layout algorithm, which originates from a more general graph visualization problem. For the initialization of the dimension reduction, a spectral layout can be used. Rather than using a random initialization like \tsne, this allows for faster convergence and better stability within the algorithm.
	The embedding is then optimized through minimizing the fuzzy set cross-entropy \citep{umap:18}.
	
	\umap was chosen over \tsne because it preserves local and global structures better than \tsne and has no restrictions of embedding dimensions \citep{umap_better:19, umap:18}.    
	\umap was used in version 0.3.9 and the main parameters were set as follows.
	The parameter \texttt{n\_neighbors} controls how \umap balances local versus global structure in the data. It describes how many neighbors should be considered when searching for defined structures. Low values mean that local structures are preferred. In contrast, larger values mean the loss of detailed structures for a broader global view of the data. Here, a value of 2 was chosen.
	\texttt{n\_components} determines the dimensionality of the reduced dimensional space in which the data is embedded. The default value was set to 10.
	\texttt{dist} controls how tightly points may be packed together. Since two sequences can be identical, a value of 0 is selected.
	The parameter \texttt{metric} controls how the distance in the space of the input data is calculated. Currently, only the Euclidean distance calculation is used. However, \umap offers a variety of other distances to use, such as Manhattan, Minkowski or Canberra distance. It is also possible to implement custom distance calculations.
	
	Next, the \umap-reduced k-mer profiles from the contigs were clustered using the tool `Hierarchical Density-Based Spatial Clustering of Applications with Noise' (\hdbscan, Version~0.8.22) \citep{hdbscan}.
	Recent viral metagenomics research has also used the combination of \umap and \hdbscan to recover high-quality viral genomes from environmental samples directly \citep{umap_hdbscan_usage:19}.
	
	\subsubsection*{HDBSCAN}
    \hdbscan converts the original \dbscan \citep{dbscan:96} into a hierarchical clustering algorithm, rather than just a density-based algorithm.
	The central assumption is that real-world data is messy and those outliers need to be separated from the actual data of interest. For this reason, a transformation of the data space is performed, utilizing a k-nearest neighbor approach to measure the core distance for each point. The core distance is defined by the furthest neighbor out of k neighbors and gives an idea of the data density. The data points are then shifted according to the density. High-density points (low core distance) stay near to their original position. However, low-density points (high core distance) are spread to be at least the core distance away from any other point. As a result, the noisy data points spread out, while original clusters nearly stay the same.
	From this dimensional representation, an undirected weighted graph is constructed, where the weight represents the mutual reachability distance, which is a distance based on the core distance. For this graph, the minimum spanning tree is calculated using Prim's algorithm.
	Subsequently, a hierarchy of connected components is created using the minimum spanning tree. Union-find is used to identify which edges join two clusters.
	Afterwards, the resulting cluster hierarchy is condensed to find actual clusters. For this purpose, a walk through the split-points of the hierarchy tree is performed. New clusters are only formed if a split-point in the tree creates two clusters that are greater than the user-provided \texttt{min\_cluster\_size} parameter. Otherwise, the walk through the tree continues.
	At last, the clusters are extracted from the condensed tree. A stability value is calculated for each cluster to identify the true clusters. In order to compare the stability of different clusters, a reverse walk through the tree is performed. For each sub-branch of the tree, the child stabilities are compared to their parent stability. If the parent has a larger stability value, the new stability value is set to the sum of the children's stability. The parent cluster becomes the child and the stability is compared to its next parent.
	However, if the stabilities of the children are higher than the stability of the parent, those clusters are selected \citep{hdbscan}.
	
	The primary parameter \texttt{min\_cluster\_size} sets the minimum group size that is considered a cluster. Since it is technically possible, that there is only one contig in a single cluster, it would be reasonable to set this option to 1. However, in this case, the underlying algorithm may produce a bias towards the root cluster \citep{hdbscan}. Therefore, the default value chosen was 2.
	This procedure then results in k-mer based clusters, as well as a large group that is called `unlabeled'. These unlabeled contigs can't be clustered by the previously named algorithms. The k-mer based information is not sufficient to assign the contigs to a specific cluster. \\
	\\
	The existing clusters were then complemented with coverage information derived from the reads. To obtain this information \salmon (Version 0.14.1) \citep{salmon:17} was chosen mainly because of its speed in calculation (Figure~\ref{img:karma_workflow}A2). 
	The high speed of calculation is a result of the quasi-mapping, which gives a rough overview of the number of reads shared by all contigs. This information is stored in an equivalence class file and used in this implementation.
	In order to perform a quasi-mapping with \salmon, an index has to be created for the transcripts. The index for the quasi-mapping was built with the parameter \texttt{-{}-keepDuplicates}. By default, \salmon discards sequence-identical duplicate transcripts. The parameter disables this behavior and treats duplicate transcripts as individual sequences.
	\salmon uses the previously built index to perform the fast quasi-mapping. The parameter \texttt{-{}-libType} was set to allow \salmon to detect the orientation and strandedness of the reads automatically.
	\texttt{-{}-validateMappings} enables a more sensitive and accurate quasi-mapping algorithm resulting in more precise results. \texttt{-{}-dumpEq} will cause \salmon to write an equivalence class file with the shared read counts between contigs that were computed during quasi-mapping.\\
\\
	The k-mer based clusters and the coverage information is then used to create a weighted undirected graph $ G = (V, E, \omega) $ for each of these clusters. These graphs consist of vertices $V$ (contigs) and the edges $E$ between them store the information from the \salmon equivalence class file. The read-graph is based on the program \grouper \citep{Grouper:18}. However, the weighting function $\omega$ for the edge weight calculation from \grouper (Equation~\ref{eq:grouper_distance}) was replaced with a custom weighting function (Equation~\ref{eq:distance}). Both equations describe the weight between two different contigs $ i $ and $ j $, where $ N $ is the number of assigned reads to the contig. So $N_{i}$/$N_{j}$ describes the amount of reads assigned to contig $i$/$j$ and $ N_{i,j}$ the amount of shared reads between $i$ and $j$.
	In short, Equation~\ref{eq:distance} is chosen over the original weighting function, because it puts more value towards individually assigned reads, resulting in more evenly distributed weights.
	\begin{equation}
		\label{eq:grouper_distance}
		\mathlarger{\omega_{ij} = \frac{N_{ij}}{\min{(N_{i}, N_{j})}}} 
	\end{equation}
	
	\begin{equation}
		\label{eq:distance}
		\mathlarger{\omega_{ij} = \frac{\frac{N_{ij}}{N_{i}} + \frac{N_{ij}}{N_{j}}}{2}} 
	\end{equation}
	
	Table~\ref{table:compare} compares the different results from the two weighting functions for variations of $N_{i}, N_{j}, N_{ij}$ that may occur between two contigs, to distinguish the different results for both equations.
	For example, Equation~\ref{eq:distance} yields the maximum best value of 1 only if all reads of contig $i$ are shared with contig $j$ (Table~\ref{table:compare}, row 1). By contrast, it is sufficient for Equation~\ref{eq:grouper_distance} that one contig shares all of its reads with the other contig, to yield the best score (Table~\ref{table:compare}, row 1-4).
	Overall, the weight from Equation~\ref{eq:distance} is lower than from Equation~\ref{eq:grouper_distance} and has a lower minimum score (Table~\ref{table:compare}, row 6).

	\begin{table}[H]
		\centering
		\captionsetup{width=0.71\linewidth}
		\caption[Comparison of the weighting function from \karma and \grouper.]{Comparison of the weighting function from \karma and \grouper. The table shows the different results for the calculation of weights.}
		\label{table:compare}
		\begin{tabular}{llrrrrrr}
			\toprule
			\multicolumn{1}{l}{\textbf{Row}} & &\multicolumn{3}{l}{\textbf{Combinations}} && \multicolumn{2}{l}{\textbf{Weight}} \\ \cmidrule{1-1} \cmidrule{3-5} \cmidrule{7-8} \addlinespace
			 & & \multicolumn{1}{c}{$N_{i}$} & \multicolumn{1}{c}{$N_{j}$} & \multicolumn{1}{c}{$N_{ij}$} && \karma & \grouper \\ \addlinespace
			\midrule
			\multicolumn{1}{c}{1} & & ~~~100 & ~~~~100 & ~~~~100 && 1 & 1 \\ \addlinespace
			\multicolumn{1}{c}{2} & & 100 & 80 & 80 && 0.9 & 1 \\ \addlinespace
			\multicolumn{1}{c}{3} & & 100 & 70 & 70 && 0.85 & 1 \\ \addlinespace
			\multicolumn{1}{c}{4} & & 100 & 50 & 50 && 0.75 & 1 \\ \addlinespace
			\multicolumn{1}{c}{5} & & 100 & 50 & 25 && 0.375 & 0.5 \\ \addlinespace
			\multicolumn{1}{c}{6} & & 100 & 50 & 1 && 0.015 & 0.02 \\ \addlinespace
			\bottomrule
		\end{tabular}
	\end{table}

	\noindent
	With this additional information based on read quasi-mappings, the next step in the pipeline assigns contigs from the unlabeled k-mer clustering to their correct cluster, according to the coverage information.
	
	\begin{figure}[H]
		\centering
		\def\svgwidth{\textwidth}
		\input{images/02_methods/karma_workflow.pdf_tex}
		\caption[Workflow scheme of \karma.]{\label{img:karma_workflow} Workflow scheme for \karma. \textbf{(A)} A pre-clustering step using k-mers is performed by \umap and \hdbscan. The existing clusters are then supplemented with the information from the equivalence classes from \salmon.
			\textbf{(B)} Cluster trimming. Each contig that doesn't share contigs with all other contigs in a k-mer based cluster is moved to an 'unclustered group'(red).
			\textbf{(C)} Cluster redefinition. Contigs from the 'unclustered group' are added to each cluster if they share reads with the specific cluster.
			\textbf{(D)} \mcl clustering \& sequence selection. The resulting groups are then clustered using \mcl. Each contig has a score equal to the sum of the weights of the edges to which it is connected. For each subgroup the contig with the highest score is chosen as representative.}
	\end{figure} 
	
    After the graph construction, cluster trimming is performed (Figure~\ref{img:karma_workflow}B). All single contigs are removed that don't share reads with all other contigs in one cluster. Those contigs are then added to the unlabeled group.
	Subsequently, the clusters are redefined using the unlabeled cluster (Figure~\ref{img:karma_workflow}C). The unlabeled group is added to each existing k-mer based cluster. If a read has a connection with one of the contigs in the original group, it remains this group. Similar to step one, all reads that have no connection are removed. This process is then repeated for each k-mer based cluster until all clusters have been paired with and separated from the unlabeled group.
	In the best case, the resulting clusters should then represent one gene with different isoforms. To extract those isoforms, the Markov Cluster Algorithm (\mcl, Version 14.137) \citep{mcl:00} is used to determine subclusters in the corrected k-mer based clusters (Figure~\ref{img:karma_workflow}D).\\
	\\
	\mcl is a graph clustering algorithm based on the simulation of random walks, which are calculated through Markov chains. The core idea is that the simulation of a random flow through a graph reveals natural clusters. The weights of the edges reflect the strength of the flow between two vertices. Respectively, a random walk starting in a dense cluster (high weights, many connections) will most likely stay in that cluster, thus gives information about the structure of the graph.
	
	The main parameter for this is the inflation value \texttt{-I}. This value is the main handle for affecting cluster granularity. A bigger value will result in finer clusterings. The allowed values range from 1.2 to 5, while the default value is set to 2.
	For each subcluster, a representative sequence has to be selected. The sum of the edge weights is calculated for every node. Subsequently, the contig with the highest overall weight is chosen as a representative sequence. This means that one cluster may have multiple representative sequences, which should represent isoforms.
	
	\begin{wraptable}{L}{8.5cm}
		\caption[Combination of parameters used for the parameter evaluation.]{Combination of parameters used for the parameter evaluation. All combinations (432) of the listed parameters were tested.}
		\label{table:comb}
		\begin{tabular}{lrrrrrr}
			\toprule
			\multicolumn{1}{l}{\textbf{Parameter}} & \multicolumn{5}{l}{\textbf{Values}} \\ \addlinespace
			\midrule
			k-mers & 3 & 5p6 & 7 &  &  &  \\ \addlinespace
			n\_neighbors & 2 & 5 & 10 & 20 &  &  \\ \addlinespace
			n\_components & 2 & 5 & 10 & 20 & 30 & 40 \\ \addlinespace
			min\_cluster\_size & 1 & 2 & 5 & 10 & 15 & 20 \\ \addlinespace
			\bottomrule
		\end{tabular}
	\end{wraptable}
	Since the pipeline has a lot of parameters that can be tuned, a parameter evaluation was done for the following combinations of parameters with the simulated dataset (Table~\ref{table:comb}).
	
	The source code of \karma is freely available on \href{https://github.com/lmfaber/karma}{GitHub} and can also be easily installed via \href{https://anaconda.org/lmfaber/karma}{Anaconda Cloud} (See Section~\ref{appendix:karma})\\

\subsection{Runtime analysis}
The time was measured for all clustering tools on a Linux-based system (Debian~9.0) with 40 cores (AMD Opteron Processor 6238, 2.6~GHz) and 500~GB of available RAM.

\subsection{Evaluation of assemblies}
	\label{ssec:evaluation}
	The metrics to compare the quality of assemblies are calculated with the following tools. 
	\blast was only used for the evaluation of different parameters (Table~\ref{table:comb}) for the simulated dataset because it is a lot faster compared to using all other tools in this section.
	The metrics from the remaining tools were selected according to \citet{hoelzer:19} and are explained in Section~\ref{ssec:comparison}.

\subsubsection*{BLAST}
	A \blast (Version 2.9.0) \citep{blast:90} search was performed to identify which gene and isoform a certain contig from the \textit{de novo} assemblies corresponds to.
	
	A custom database was created from the original protein and non-protein coding sequences of the first chromosome of \celegans.
	The assembly was then blasted against the database and the hit with the highest sequence similarity and lowest e-value was chosen as the `true' gene/isoform. With the information from the \blast results, the clusters were analyzed for intra and inter cluster similarity.
	
	The purity of all clusters was measured using the intra cluster similarity, where $ C $ denotes the total amount of clusters. For each cluster~$ i \in C $, the most common gene $ N_{i, com} $ was selected to be the `true' gene and was compared to the total cluster size $ S_{i} $. The overall intra cluster similarity is achieved by calculating the mean value of all intra cluster similarities (Equation~\ref{eq:intra}). The best value is a 1 and a lower score means a lower intra cluster similarity.
	
	\begin{equation}
	\label{eq:intra}
	\mathlarger{\frac{\sum\limits_{i=1}^{C}\frac{N_{i, com}}{S_{i}}}{C} }
	\end{equation}
	
	The outer cluster similarity describes the proportion of dispersal of all genes $G$ between all clusters (Equation~\ref{eq:inter}). For every gene $i \in G$ the amount of clusters in which gene $i$ is present, is denoted as $ C_{i} $. In theory, each gene should be exactly in one cluster, leading to an optimal score of 1. Lower scores mean higher distributed genes among clusters.

	\begin{equation}
	\label{eq:inter}
	\mathlarger{\frac{G}{\sum\limits_{i=1}^{G} C_{i} }}  
	\end{equation}

\subsubsection*{DETONATE}
	`DE novo TranscriptOme rNa-seq Assembly with or without the Truth Evaluation' (DETONATE, Version 1.11) \citep{DETONATE:14} is an evaluation tool that consists of the two packages RSEM-EVAL and REF-EVAL.
	RSEM-EVAL produces an evaluation score that is based only on an assembly and the set of reads from which it was constructed.
	For example, the support of the assembly through the reads and the compactness of the assembly are used among other factors, for the calculation of this score.
	When a reference transcript set is available, REF-EVAL may be used to compute a number of reference-based measures.    \detonate was used as proposed on their \href{http://deweylab.biostat.wisc.edu/detonate/vignette.html}{online vignette}.
	
\subsubsection*{rnaQUAST}
	\rnaquast (Version 1.5.1) \citep{rnaQUAST:16} provides a wide variety of basic statistics like N50 or length distribution, but also reference-based metrics such as the number of genes, isoforms or duplication ratio. For the calculation of the latter \rnaquast needs the reference genome and the corresponding annotation.
	
\subsubsection*{TransRate}
	\transrate \citep{TransRate:16} is specifically designed to evaluate \textit{de novo} transcriptome assemblies without a reference to detect common artifacts such as chimeras, structural errors, an incomplete assembly and base errors. The tool calculates individual scores for each contig from which the entire assembly is then evaluated. These individual scores can not only be used to evaluate assemblies but also for their optimization. \transrate only accepts paired-end reads, which is the reason it is not used to evaluate single-end assemblies.
	Since Smith-Unna reported bugs affecting the calculated metrics, \transrate was used in version 1.0.1 rather than 1.0.3\footnote{\href{https://gitter.im/blahah/transrate}{https://gitter.im/blahah/transrate} (Accessed 2019-09-18); Quote from the author: `Yes - there's a bug in 1.0.3 - trust the scores from 1.0.1.'}.
	
\subsubsection*{HISAT2}
	\hisat (Version 2.1.0) \citep{hisat2:15} was used to map the reads back to contigs of the assembly to calculate the remapping rate. The percentage of mapped reads is then divided by the total number of bases, setting it into relation to the size of the assembly.
	
\subsubsection*{BUSCO}
	Benchmarking Universal Single-Copy Orthologs (\busco, Version 3.0.2) \citep{busco:15,busco:18} evaluates a given assembly in terms of completeness of gene content. The necessary databases were obtained from their website and are also found in the \href{https://github.com/lmfaber/master_thesis/blob/master/supplemental_data/busco_databases.txt}{supplemental data} (See Section~\ref{appendix:supplements}).
	\vfill

\subsubsection*{Trinity and Salmon}
    The N50 statistics is one traditional way of measuring assemblies in terms of contiguity. 
	It describes the length of the shortest contig so that the summed up nucleotides of all contigs equal or longer than that size cover 50~\% of the total nucleotides of the assembly. Thus, the N50 statistic can be used as a measurement for assembly contiguity and fragmentation and is frequently used in genomics.
	The Ex90N50 value is the same metric but only calculated on a subset of the assembly, by taking into account the expression of transcripts. The subset for the metric contains the top 90~\% of the highest expressed transcripts from the total normalized expression data. 
	Thus, low expressed and short transcripts that might dominate a transcriptome assembly do not affect the N50 value that much.
	The necessary transcript abundance estimation for this metric was calculated using \salmon (Version 0.14.1) \citep{salmon:17}. The Ex90N50 values were calculated using scripts that are included in \trinity (Version 2.8.4) \citep{Trinity:11}.
	\\
	\\
	The evaluation tools except \blast were also combined into a \snakemake pipeline and can be accessed via \href{https://github.com/lmfaber/evaluation}{GitHub} (See Section~\ref{appendix:pipelines}).
	
	\subsection{Sequence alignments}
	All sequence alignments in this thesis were calculated with \muscle (Verion~3.8.31) \citep{muscle:04}.
	
	\subsection{Visualization}
	Venn diagrams were created with the \intervene web service \citep{intervene:17}. The alignments from \muscle were visualized with \jalview (Version~2.11.0) \citep{jalview:09}.
	
	\subsection{Workflow management}
	\subsubsection*{Snakemake}
	\snakemake is a workflow manager using python as the underlying programming language. The workflows for the creation of transcriptome assemblies, clustering and evaluation, as mentioned above, were created using \snakemake in version 5.5.0 \citep{Snakemake:12}.


%%%%%%%%%%%%%%%
%%% Results %%%
%%%%%%%%%%%%%%%
\newpage
\section{Results}
	\label{sec:results}
	
	The following figures and tables in this section use some aliases, which are explained as follows. `Combined' describes a concatenation of all three assemblies from \spades, \soap and \trinity. The percentage of the sequence identity threshold is added as a number behind \cdhit. \grouper has both parameters \texttt{orphan} and \texttt{mincut} enabled, whereas \grouper{}* has them disabled.
	\karma uses the default parameters described in Section~\ref{sssec:karma} and \karma{}* describes the run with the optimized parameters from Section~\ref{ssec:parameter}.
	
	\subsection{Different assemblers yield distinct genes and isoforms}
	For the simulated paired-end dataset, the assemblies from \spades, \trinity and \soap were annotated via a \blast search (See Section~\ref{ssec:evaluation}).
	In total, the three assemblers produce 3,235 genes and 3,925 isoforms together (Figure~\ref{img:difference}).
	However, 382 genes (16~\%) and 747 isoforms (32~\%) are produced solely by individual assemblers. The assembly from \spades contains the most individual genes (270), whereas \trinity (42) and \soap (70) contain much less (Figure~\ref{img:difference}A). Likewise, \spades produces the most individual isoforms (327), while \soap (277) and \trinity (143) produce at least 50 isoforms less (Figure~\ref{img:difference}B). 
	\begin{figure}[H]
		\def\svgwidth{\textwidth}
		\input{images/03_results/venn.pdf_tex}
		\caption[Intersection of annotated transcripts from the different assemblies.]{Intersection of annotated transcripts from the different assemblies. The transcripts were produced by \spades, \soap and \trinity for the simulated paired-end \celegans dataset. Visualization created with \intervene \citep{intervene:17}. \textbf{(A)}~Intersection of distinct unique genes. \textbf{(B)}~Intersection of distinct unique isoforms.}
		\label{img:difference}
	\end{figure}
	
	\subsection{Smaller k-mer sizes are beneficial for \texttt{karma} clustering}
	\label{ssec:parameter}
	
	Besides the default selection of parameters (formated italics), Table~\ref{table:parameter} lists all parameter combinations that yield the best results for the selected evaluation metrics.
	\hdbscan creates a certain \textit{number of groups} as well as \textit{unlabeled} sequences with no assigned groups. Furthermore, the algorithm calculates a probability for each contig that describes the specific certainty of it belonging to a cluster. The \textit{mean probability} combines all those scores and gives an impression of the clustering's reliability. The inner and outer cluster homogeneity are described in Section~\ref{ssec:evaluation}. Additionally, the percentages of genes/isoforms give an impression of the proportion of recovered genes from the original dataset.
	
		\begin{table}[H]

		%% local redefinitions
		\renewrobustcmd{\bfseries}{\fontseries{b}\selectfont}
		\renewrobustcmd{\boldmath}{}
		\caption[A selection of the best results for different parameters for \karma.]{A selection of the best results for different parameters for \karma. The best results are highlighted in bold. The initial parameter combination is listed in italics.}
		\label{table:parameter}
		\resizebox{\textwidth}{!}{%
			\begin{tabular}{rrrrrrrrrrrr}
				\toprule
				\multicolumn{4}{l}{\textbf{Parameters}} &  & \multicolumn{7}{l}{\textbf{Results}} \\ \cmidrule{1-4} \cmidrule{6-12} \addlinespace
				\textbf{\begin{tabular}[c]{@{}c@{}}k-mer\\ size\end{tabular}} & \textbf{n\_neighbors} & \textbf{n\_components} & \textbf{\begin{tabular}[c]{@{}c@{}}min\\ cluster\\ size\end{tabular}} &  & \textbf{\begin{tabular}[c]{@{}c@{}}Unlabeled\\sequences\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}No. of\\groups\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Mean\\ probability\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}}Inner\\ cluster\\ homogeneity\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}} Outer\\ cluster\\ homogeneity\end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}} Genes\\ \big[\%\big] \end{tabular}} & \textbf{\begin{tabular}[c]{@{}c@{}} Isoforms\\ \big[\%\big] \end{tabular}} \\ \addlinespace
				\midrule
				3 & 2 & 30 & 2 &  & 2,324 & \textbf{2,846} & 0.6752 & 0.9535 & 0.5240 & 41.28 & 30.06 \\ \addlinespace
				3 & 2 & 40 & 20 &  & 8,043 & 181 & 0.4118 & 0.9962 & 0.3432 & 62.18 & \textbf{47.69} \\ \addlinespace
				3 & 10 & 10 & 20 & & \textbf{6} & 4 & 0.9753 & 0.9989 & 0.6061 & 62.90 & 44.92 \\ \addlinespace
				\textit{5p6} & \textit{2} & \textit{10} & \textit{2} & & \textit{2688} & \textit{2604} & \textit{0.6617} & \textit{0.9337} & \textit{0.5218} & \textit{43.99} & \textit{32.21} \\ \addlinespace
				
				5p6 & 10 & 2 & 20 &  & 128 & 12 & 0.9826 & 0.9975 & 0.5888 & \textbf{63.00} & 45.20 \\ \addlinespace
				5p6 & 20 & 5 & 20 &  & 74 & 6 & 0.9875 & \textbf{0.9993} & \textbf{0.6390} & 30.43 & 20.90 \\ \addlinespace
				5p6 & 20 & 30 & 20 &  & 18 & 3 & \textbf{0.9973} & 0.9990 & 0.6387 & 30.43 & 20.90 \\ \addlinespace
				\bottomrule
			\end{tabular}%
		}
	\end{table}
	
    The initial selection doesn't get the highest score in any of the evaluated categories but is listed for comparison purposes.
	Noticeably, the combination that results in the fewest unlabeled contigs (6) only generates four groups and has a high mean probability (0.9753). Additionally, the parameter combinations that yield the best mean probability (0.9973), inner cluster homogeneity (0.9993), outer cluster homogeneity (0.6390), highest recovered genes (63~\%) and the highest rate of recovered isoforms (47.69~\%) all have fewer than 181 groups produced by \hdbscan. There are only two combinations that generate approximately $\sim$2,700 initial groups. Moreover, the inner cluster homogeneity is bigger than 0.95 for every combination and comparatively, the outer cluster homogeneity fluctuates between $\sim$0.34 and $\sim$0.63.
	
	Since the aim is to achieve a more complete assembly, the parameters that yield the most isoforms are selected for further evaluation even though they have the lowest outer cluster homogeneity (0.34) and lowest mean probability (0.41) among the shown parameter combinations. These parameters are used as a separate clustering for the examined datasets (\karma{}*).
	Contrarily, the parameter combination with the highest number of recovered genes (63~\%) has a higher outer cluster homogeneity (0.58) and a better mean probability (0.98).
	In general, it appears that small k-mer sizes (3-mer and 5p6-mer) are beneficial for the clustering process since the k-mer size of seven isn't among the listed parameter selection.
	The full parameter evaluation is accessible in the \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/parameter_evaluation}{supplemental data} (See Section~\ref{appendix}).


	\subsection{Runtime analysis reveals \texttt{Linclust} as fastest clustering tool}
		
        The captured runtimes for the different clustering tools are listed in Table~\ref{table:runtimes}. Since the \orp only works for paired-end data, there is no runtime available for single-end data. With a maximum of eight seconds for the single-end \celegans dataset (ERR2886543), \linclust yields by far the shortest runtimes for all samples.

		The runtimes for both versions of \mclust range from 44 seconds (simulated dataset, \mclusttwo) up to 49 minutes (ERR779269, \mclust), but generally don't differ too much from each other.
		For the two distinct runs of \cdhit, the difference is more noticeable. With a sequence identity of 90~\% (c=0.9), \cdhit usually takes longer than with a sequence identity of 100~\%. The longest run ($\sim$12 hours) of \cdhit (c=0.9) was measured for the single-end \celegans dataset (ERR2886543) and the shortest ($\sim$5 minutes) for the single-end \ecoli dataset (SRR4255368).
		\begin{table}[H]
			\caption[Runtime (hh:mm:ss) of the different clustering methods for each dataset.]{Runtime (hh:mm:ss) of the different clustering methods for each dataset. The best runtime per sample is marked bold. No runtime is available for single-end datasets for the \orp because it only works with paired-end data. Paired-end data: PE, Single-end data: SE.}
			\renewrobustcmd{\bfseries}{\fontseries{b}\selectfont}
			\renewrobustcmd{\boldmath}{}
			\resizebox{\textwidth}{!}{%
				\begin{tabular}{@{}lrrrrrrr@{}}
					\toprule
					\multicolumn{1}{l}{\textbf{Clustering method}} & \multicolumn{1}{l}{\textbf{}} & \multicolumn{1}{l}{\textbf{\celegans}} & \multicolumn{1}{l}{\textbf{}} & \multicolumn{1}{l}{\textbf{}} & \multicolumn{1}{l}{\textbf{}} & \multicolumn{1}{l}{\textbf{\ecoli}} & \multicolumn{1}{l}{\textbf{}} \\\cmidrule{1-1} \cmidrule{3-5} \cmidrule{7-8} \addlinespace 
					& \multicolumn{1}{l}{} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}SRR5456164\\ (PE)\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}ERR2886543\\ (SE)\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}FLUX\\ (PE)\end{tabular}}} & \multicolumn{1}{c}{\textbf{}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}ERR779269\\ (PE)\end{tabular}}} & \multicolumn{1}{c}{\textbf{\begin{tabular}[c]{@{}c@{}}SRR4255368\\ (SE)\end{tabular}}} \\ \addlinespace
					\midrule
					
					\cdhit{}-100 &  & 00:22:20 & 00:34:41 & 00:01:33 &  & 02:58:47 & 00:00:47 \\ \addlinespace
					\cdhit{}-90 &  & 02:44:36 & 12:03:22 & 00:23:03 &  & 04:57:00 & 00:04:50 \\ \addlinespace
					\linclust &  & \textbf{00:00:05} & \textbf{00:00:08} & \textbf{00:00:03} &  & \textbf{00:00:04} & \textbf{00:00:03} \\ \addlinespace
					\mclust &  & 00:02:31 & 00:04:24 & 00:02:07 &  & 00:49:10 & 00:00:44 \\ \addlinespace
					\mclusttwo &  & 00:07:34 & 00:06:19 & 00:00:43 &  & 00:01:04 & 00:00:42 \\ \addlinespace
					\grouper &  & 21:59:22 & 00:45:52 & 00:03:29 &  & 00:01:48 & 01:27:00 \\ \addlinespace
					\grouper{}* &  & 23:22:52 & 00:46:13 & 00:03:36 &  & 00:01:37 & 01:19:42 \\ \addlinespace
					\karma &  & 07:41:40 & 12:46:45 & 00:26:52 &  & 00:08:04 & 00:28:04 \\ \addlinespace
					\karma{}* &  & 00:48:06 & 00:39:20 & 00:03:36 &  & 00:05:11 & 00:06:22 \\ \addlinespace
					\orp & & 11:39:50 & N/A & 00:31:33 &  & 05:53:03 & N/A \\ \bottomrule
				\end{tabular}%
			}
			\label{table:runtimes}
		\end{table}
        \cdhit (c=1) clusters the single-end \ecoli dataset (SRR4255368) in roughly a minute and takes approximately 3 hours for the paired-end \ecoli dataset (ERR779269).
		Out of all clustering tools, both \grouper runs for the paired-end \celegans dataset (SRR5456164) take longer than 21 hours to complete. However, for all other datasets, the runtime is lower than 1 hour.
		Besides \cdhit and \grouper, \karma is also a program that has a runtime in the range of hours for individual datasets. For example, \karma needs approximately eight hours for the paired-end \celegans dataset and 13 hours for the single-end \celegans dataset. For all other datasets, its runtime lies within the range of minutes. \karma{}* reveals a similar pattern. Yet, the runtime for the full \celegans datasets is $\sim$40~minutes each, the maximum time needed for the other datasets is $\sim$5 minutes. In general, karma{}* takes less time than \karma.
		The \orp takes between $\sim$30 minutes and $\sim$12 hours for the paired-end datasets.

	\subsection{Coverage information complements k-mer based clusters}
	\label{ssec:graphs}
	This section visualizes \karma{}'s clustering process of the artificial paired-end \celegans dataset for an in-depth understanding of the clustering process. During the k-mer based clustering, trimming and cluster redefinition, several cases may occur. These cases are exemplarily shown (Figures~\ref{img:cluster28}-\ref{img:cluster660}) and described in the following three subsections. All other graphs are accessible in the \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/graphs}{supplemental data} (See Section~\ref{appendix:supplements}).
	
	\subsubsection*{Case 1}
        After k-mer based clustering, cluster 28 contains seven contigs with six different isoforms (Annotation IDs: F27D4.5.1, T03F1.1.2, Y37E3.13a.1, B0511.8.2, C09D4.3.1, Y37E3.15a.1, see Figure~\ref{img:cluster28}A). 
        Note that even though Y37E3.13a.1 and Y37E3.15a.1 have a similar name, they originate from different genes. The isoform F27D4.5.1 is produced both by \spades and \trinity and connected with a weight of 0.92. All other contigs are present as single vertices (Figure~\ref{img:cluster28}A). Consequently, the cluster trimming step removes those and during the cluster redefinition process, another contig is added to the graph. This new contig was produced by \soap and is connected to both other contigs with a weight of $\sim$0.9 (Figure~\ref{img:cluster28}B). \mcl clustering selects only one contig as a representative sequence. 
        The sequence alignment for the final cluster 28 shows that the transcripts are highly similar, while the contig produced by \soap is with 1181~nt about 246~nt shorter than the other two sequences (See Section~\ref{appendix:supplements}, Figure~\ref{img:aln:case1}).

		\begin{figure}[H]
			\centering
			\def\svgwidth{\textwidth}
			\input{images/03_results/graphs/cluster_28.pdf_tex}
			\caption[In-depth clustering process of \karma (Case 1).]{In-depth clustering process of \karma (Case 1). Cluster 28 of clustering the artificial paired-end dataset. \textbf{(A)} K-mer based cluster produced by \hdbscan complemented with the calculated weights from the quasi-mapping information. The cluster contains six different isoforms (Annotation IDs: F27D4.5.1, T03F1.1.2, Y37E3.13.a.1, B0511.8.2, Y37E3.15a.1, C09D4.3.1) of which two are connected with a weight of 0.92. \textbf{(B)} Cluster after trimming and cluster redefinition. The asterisk marks the selected representative sequence for this cluster. The single vertices were removed and a new vertice is added via cluster redefinition.}
			\label{img:cluster28}
		\end{figure}
		
	\subsubsection*{Case 2}
	
		Figure~\ref{img:cluster455a} shows cluster 455 after trimming and redefinition. It contains two different isoforms (Annotation IDs: C25A1.10a.2 and C25A1.10b.2) that are produced by \trinity and \soap. 
		Two contigs of isoform C25A1.10a.2 were produced by \soap and are connected with a weight of 0.952. 
		Contrarily, \trinity created two contigs of two isoforms, C25A1.10a.2 and C25A1.10b.2, that are connected with a weight of 0.529.
		\begin{figure}[H]
			\centering
			\def\svgwidth{0.7\textwidth}
			\input{images/03_results/graphs/cluster_455_A.pdf_tex}
			\caption[In-depth clustering process of \karma (Case 2).]{In-depth clustering process of \karma (Case 2). Cluster 455 of clustering the artificial paired-end dataset after trimming and cluster redefinition. The cluster contains two different isoforms (Annotation IDs: C25A1.10a.2 and C25A1.10b.2). \mcl clustering selects two distinct representative sequences (asterisk).}
			\label{img:cluster455a}
		\end{figure}
		The edges between the contigs from \soap and \trinity are smaller than 0.03, which leads to two representative sequences during \mcl clustering.
		The contigs from each assembler are quite similar to each other. However, the sequences from \soap are significantly longer than those from \trinity, thus impairing the quality of the alignment (See Section~\ref{appendix:supplements}, Figure~\ref{img:aln:case2}).
		
	\subsubsection*{Case 3}
        The last case shows cluster 660 before trimming and redefinition. Figure~\ref{img:cluster660} shows five contigs and three isoforms (Annotation IDs: T20F10.1.1, T19B4.7.1, F25D7.5.1). The trimming process removes the isoform F25D7.5.1 and the redefinition does not add new sequences to the cluster (not shown).
		However, the two other isoforms are both represented by two contigs from different assemblers. Based on the coverage information, the edges between the two contigs of each isoform have a weight of 1. \mcl clustering yields two representative sequences for this cluster. 
		The sequences of two transcripts of the same isoform are concurring, while the sequences between two isoforms are quite different. Furthermore, the sequences for isoform T19B4.7.1 are only approximately 250~nt long and the sequences for isoform T20F10.1.1 are approximately 700~nt long (See Section~\ref{appendix:supplements}, Figure~\ref{img:aln:case3}).
	
		\begin{figure}[H]
			\centering
			\def\svgwidth{0.7\textwidth}
			\input{images/03_results/graphs/cluster_660_A.pdf_tex}
			\caption[In-depth clustering process of \karma (Case 3).]{In-depth clustering process of \karma (Case 3). Cluster 660 of clustering the artificial paired-end dataset before trimming and cluster redefinition. The cluster contains three different isoforms (Annotation IDs: T20F10.1.1, T19B4.7.1, F25D7.5.1). \mcl yields two representative sequences for this cluster (asterisk).}
			\label{img:cluster660}
		\end{figure}

	\newpage
	\subsection{The size of the clustered assemblies varies greatly}

	\subsubsection*{Simulated \celegans dataset}
	    Figure~\ref{img:barchart_flux} represents the size of all three assemblies, the concatenation, as well as the clusterings for the simulated \celegans dataset.
		The concatenated assembly has 15,908 sequences, which originate from the assemblies with sizes between 4,300 and 6,300 sequences in total.
		The size of the assemblies after clustering varies significantly between two (\grouper) and 14,033 (\mclust) sequences and the number of reproduced genes hover around 3,000 except for \karma and \grouper. The number of isoforms is always slightly higher, with a maximum of 3,872 isoforms for \mclust.
		Of the two sequences extracted from \grouper, none of them represents a gene from the original dataset.
		Both \karma runs produce around 3,000 to 4,000 sequences, with roughly 1,500 genes recovered, which is only about half the amount compared to other clustering methods.
	
	\begin{figure}[H]
		\centering
		\def\svgwidth{\textwidth}
		\input{images/03_results/barcharts/cel_flux_barchart.pdf_tex}
		\caption[The number of sequences in each (clustered) assembly (PE, CEL\_FLUX).]{The number of sequences (grey bar) in each (clustered) assembly for the simulated \celegans dataset (CEL\_FLUX). The number of genes/isoforms of each assembly were evaluated via a \blast search against the original data. The orange/blue bars represent the number of unique genes/isoforms in each assembly.}
		\label{img:barchart_flux}
	\end{figure}
		\newpage
		When looking at the length distribution of the assemblies and clusterings, it is noticeable that the extracted sequences from \grouper have a median length of $\sim$25,000~nt (Figure~\ref{img:violin_flux}). This is far above all other assemblies where the medians lie around 200--600~nt. 
		Additionally, the longest sequences of all other assemblies are also around 25,000~nt long.
		Furthermore, the clusterings from \karma and \mclusttwo consist of comparatively shorter median sequence lengths ($\sim$220~nt).
		Interestingly, the shortest sequence of the \orp is with $\sim$100~nt nearly twice as long compared to the shortest sequences from all other clustering methods.
		The \orp and \cdhit (c=1) show a higher proportion of long sequences.
		Considering only single-tool assemblies, \soap produces an assembly of rather small sequence lengths (Median: 255~nt) with the shortest sequence being 51~nt long. 

	\begin{figure}[H]
		\centering
		\def\svgwidth{\textwidth}
		\input{images/03_results/violin/cel_flux.pdf_tex}
		\caption[Distribution of transcript lengths per assembly (PE, CEL\_FLUX)]{Distribution of transcript lengths in each (clustered) assembly for the simulated \celegans dataset (CEL\_FLUX). The $\log_{10}$ scale reaches from 10~nt (10\textsuperscript{1}) to $\sim$31,622~nt (10\textsuperscript{4.5}). The width of the violin is normalized and provides information about length distribution, but not the actual number of sequences. Blue: Single assemblers, Orange: Concatenation of the blue assemblies, Green: Different clustering methods based on the `Combined' set. Purple: The \orp that relies on its own internal assemblies. The red line represents the median sequence length and the dotted grey lines mark the quartiles.}
		\label{img:violin_flux}
	\end{figure}

\subsubsection*{\celegans datasets}

	    Figure~\ref{img:barcharts:cel} shows the sizes of the assemblies from both \celegans datasets.
		Comparing only single assemblers, \spades produces the largest assembly for the paired-end dataset (SRR5456164) and \soap the largest assembly for the single-end dataset (ERR2886543).
		Regarding the clusterings, \grouper and \karma produce very few sequences through clustering for both datasets. However, \karma yields up to 8,056 sequences for the single-end dataset and 7,608 sequences for the paired-end dataset. Additionally, \grouper returns three sequences for the single-end dataset and 53 sequences for the paired-end dataset for both runs, respectively.
		Looking at the numbers from \cdhit, one can see that the clusterings with a smaller identity threshold are smaller for both datasets compared to those with a higher identity threshold.
		\begin{figure}[H]
			\centering
			\def\svgwidth{\textwidth}
			\input{images/03_results/barcharts/cel.pdf_tex}
			\caption[Number of sequences for each (clustered) assembly in the \celegans datasets.]{Number of sequences for each (clustered) assembly in the \celegans datasets. Single-end dataset: ERR2886543. Paired-end dataset: SRR5456164. There is no \orp clustering available for the single-end dataset.}
			\label{img:barcharts:cel}
		\end{figure}
	\noindent
		Interestingly, \mclust and \mclusttwo produce very distinct results between the two datasets. \mclust returns more sequences (52,678) than \mclusttwo (26,578) for the single-end dataset. Contrarily, for the paired-end dataset, those numbers are swapped. Thus more sequences are reported from \mclusttwo.
		As mentioned in Section~\ref{ss:clustering}, there is no clustering available for the single-end dataset from the \orp.


    To complement the information from Figure~\ref{img:barcharts:cel}, the following Figures show the length distribution for each assembly for the paired-end (Figure~\ref{img:violin:cel_SRR5456164}) and the single-end dataset (Figure~\ref{img:violin:cel_ERR2886543}).
    		\begin{figure}[H]
    	\centering
    	\def\svgwidth{\textwidth}
    	\input{images/03_results/violin/cel_SRR5456164.pdf_tex}
    	\caption[Distribution of transcript lengths per assembly (PE, SRR5456164)]{Distribution of transcript lengths in each (clustered) assembly for the paired-end \celegans dataset (SRR5456164). The $\log_{10}$ scale reaches from 10~nt (10\textsuperscript{1}) to $\sim$10,000~nt (10\textsuperscript{4}). The width of the violin is normalized and provides information about length distribution, but not the actual number of sequences. Blue: Assemblers, Orange: Concatenation of the blue assemblies, Green: Different clustering methods based on the `Combined set'. Purple: The \orp that relies on its own internal assemblies. The red line represents the median sequence length and the dotted grey lines mark the quartiles.}
    	\label{img:violin:cel_SRR5456164}
    \end{figure}
	For the paired-end dataset, \trinity produces fewer small contigs compared to \soap and \spades. \trinity's shortest contig is 197~nt long, whereas \spades and \soap provide the shortest contig length of 50~nt.
	The median sequence length doesn't have a huge difference throughout all different tools and varies between 197~nt (\mclust) and 344~nt (\grouper). Both \grouper runs also contain the longest contig with a length of 67,791~nt.
	Note that \grouper contains multiple versions of large contigs ($\sim$6200~nt) and therefore, the violin plot seems to reach values of up to 10,000~nt even though there are no actual sequences of that length. This is due to the way the data is represented through the violin plot.
	Additionally, the \orp and both runs from \grouper have a minimum sequence length of $\sim$100~nt, which is twice as long as the shortest sequence for all other clustering tools.


    Looking at the single-end dataset, the median sequence lengths of all tools vary again (Figure~\ref{img:violin:cel_ERR2886543}).
    \begin{figure}[H]
    	\centering
    	\def\svgwidth{\textwidth}
    	\input{images/03_results/violin/cel_ERR2886543.pdf_tex}
    	\caption[Distribution of transcript lengths per assembly (SE, ERR2886543)]{Distribution of transcript lengths in each (clustered) assembly for the single-end \celegans dataset (ERR2886543). The $\log_{10}$ scale reaches from 10~nt (10\textsuperscript{1}) to $\sim$10,000~nt (10\textsuperscript{4}). The width of the violin is normalized and provides information about length distribution, but not the actual number of sequences. Blue: Assemblers, Orange: Concatenation of the blue assemblies, Green: Different clustering methods based on the `Combined set'. The red line represents the median sequence length and the dotted grey lines mark the quartiles.}
    	\label{img:violin:cel_ERR2886543}
    \end{figure}
	Regarding the assemblers, \soap produces the broadest spectrum of sequence lengths between 26~nt and 14,243~nt with mostly shorter sequences (Median: 184~nt). Contrarily, \trinity has a median sequence length of 625~nt that ranges from 200~nt up to $\sim$14,000~nt.
	
	\cdhit, \linclust and \mclust have a similar distribution of sequence lengths with a median of $\sim$210~nt. However, the longest sequence from \mclust is only 5237~nt long, whereas the longest sequences from the other tools are around 14,000~nt long.
	Again, the three sequences of \grouper are all long sequences with a median of $\sim$13,000~nt.
	\mclusttwo has the lowest median (134~nt) while still containing sequences of the length of $\sim$14,000~nt.
	The distribution between long and short sequences is balanced the most for \karma with a median sequence length of around 450~nt.



\subsubsection*{\ecoli datasets}

    Equivalent to the \celegans datasets, Figure~\ref{img:barcharts:ecos} describes the number of sequences per assembly and the clustered concatenation of the two \ecoli datasets.
	For the single-end dataset, the produced assemblies from \spades, \trinity and \soap vary widely. While \soap produces up to 13,059 sequences, \trinity yields only 2,443 contigs. For the paired-end dataset, \spades produces 3,351 contigs, which are about 50~\% of the amount that \spades produces for the single-end dataset.
	Also, as mentioned in the \celegans section, \cdhit with a higher sequence similarity produces more sequences for both \ecoli datasets. The smallest clusterings are once again produced by \grouper and \karma. \grouper yields only two sequences for both runs and \karma has 1,058 sequences for the paired-end dataset and 2,414 for the single-end dataset. With alternative parameters (\karma{}*), the clustering only contains around 600 sequences for both datasets.
	The other clustering tools produce assemblies with 11,780 sequences (\cdhit, c=0.9) up to 18,299 sequences (\mclusttwo) for the single-end dataset.
	Contrarily, for the paired-end dataset, the \orp, \cdhit, \linclust, \mclust and \mclusttwo produce between 3,323 (\cdhit, c=0.9) and  7,014 sequences.
	Again, the clusterings for the single-end dataset contain way more sequences than those from the paired-end datasets, which is a result of the smaller assemblies from \spades, \soap and \trinity.
	\begin{figure}[H]
	\centering
	\def\svgwidth{\textwidth}
	\input{images/03_results/barcharts/eco.pdf_tex}
	\caption[Number of sequences for each (clustered) assembly in the \ecoli datasets.]{Number of sequences for each (clustered) assembly in the \ecoli datasets. Single-end dataset: SRR4255368. Paired-end dataset: ERR779269. There is no \orp clustering available for the single-end dataset.}
	\label{img:barcharts:ecos}
\end{figure}
	
    Figure~\ref{img:violin:eco_ERR779269} shows the contig length distribution for the paired-end \ecoli dataset.
	Considering only assemblers, \trinity produces overall a bigger amount of long sequences (Median: 593~nt) compared to \soap (Median: 404~nt) and \spades (Median: 192~nt).
	From all clusterings, \grouper once again has only a few very long sequences with a median sequence length of 112,170~nt.
	Interestingly, the \orp pipeline produced a longer contig (143,831~nt) than all other contigs produced by the individual runs by \spades, \soap and \trinity. Nevertheless, the big majority of sequence lengths are around 200~nt.
	For the remaining tools, the clustered assemblies have an equal distribution of sequence length, while most of the sequences are short contigs (Median $\sim$150-260~nt).
	\begin{figure}[H]
	\centering
	\def\svgwidth{\textwidth}
	\input{images/03_results/violin/eco_ERR779269.pdf_tex}
	\caption[Distribution of transcript lengths per assembly (PE, ERR779269)]{Distribution of transcript lengths in each (clustered) assembly for the paired-end \ecoli dataset (ERR779269). The $\log_{10}$ scale reaches from 10~nt (10\textsuperscript{1}) to $\sim$100,000~nt (10\textsuperscript{5}). The width of the violin is normalized and provides information about length distribution, but not the actual number of sequences. Blue: Assemblers, Orange: Concatenation of the blue assemblies, Green: Different clustering methods based on the `Combined set'. Purple: The \orp that relies on its own internal assemblies. The red line represents the median sequence length and the dotted grey lines mark the quartiles.}
	\label{img:violin:eco_ERR779269}
\end{figure}


    Contrarily to the paired-end dataset, the maximum contig length of all assemblers is only 5,140~nt for the single-end dataset (Figure~\ref{img:violin:eco_SRR4255368}).
	\soap produces contigs with a length between 27--5,112~nt. On the other hand, \spades (Median: 159~nt) and \trinity (Median: 332~nt) have a higher proportion of long sequences.
	Once more, \grouper has the highest median sequence length of 4,062. \karma's median sequence length is slightly higher compared to the other tools ($\sim$200~nt). \cdhit, \linclust, \mclust and \mclusttwo have a median sequence length of approximately 120~nt with a similar length distribution. However, \mclust's longest sequence is only about $\sim$2,400~nt long compared to the other tools ($\sim$5,100~nt).

	\begin{figure}[H]
		\centering
		\def\svgwidth{\textwidth}
		\input{images/03_results/violin/eco_SRR4255368.pdf_tex}
		\caption[Distribution of transcript lengths per assembly (SE, SRR4255368)]{Distribution of transcript lengths in each (clustered) assembly for the single-end \ecoli dataset (SRR4255368). The $\log_{10}$ scale reaches from 10~nt (10\textsuperscript{1}) to $\sim$10,000~nt (10\textsuperscript{4}). The width of the violin is normalized and provides information about length distribution, but not the actual number of sequences. Blue: Assemblers, Orange: Concatenation of the blue assemblies, Green: Different clustering methods based on the `Combined set'. The red line represents the median sequence length and the dotted grey lines mark the quartiles.}
		\label{img:violin:eco_SRR4255368}
	\end{figure}


	
	\subsection{\texttt{cd-hit-est} outperforms other clustering tools}
		\label{ssec:comparison}
		The metrics used to evaluate the datasets are explained as follows. The arrows behind each metric show if a low ($\downarrow$) or high ($\uparrow$) value for this metric is considered good.

		\begin{itemize}
			\item \textbf{\rnaquast} \citep{rnaQUAST:16}
				\begin{itemize}
					\item \textbf{Database coverage ($\uparrow$):} The total number of bases covered by reads (in all isoforms) divided by the total length of all isoforms. 
					\item \textbf{Duplication ratio ($\downarrow$):} The total number of aligned bases in assembled transcripts divided by the total number of isoform covered bases. This metric counts neither paralogous genes nor shared exons, only real overlaps of the assembled sequences that are mapped to the same isoform.
					\item \textbf{95~\%-assembled isoforms ($\uparrow$):} The number of isoforms from the database that have at least 95~\% captured by a single assembled transcript.
					\item \textbf{Misassemblies ($\downarrow$):} The number of misassembled transcripts calculated from \gmap \citep{gmap:05} and \blastn \citep{blast:90}.
				\end{itemize}
			\item \textbf{\transrate} \citep{TransRate:16}
				\begin{itemize}
					\item \textbf{Mean open reading frame (ORF) percentage ($\uparrow$):} For all contigs that contain a ORF, the mean percentage of contigs covered by the ORF.
					\item \textbf{Assembly score ($\uparrow$):} \transrate'{s} basic idea is to calculate a contig score for each transcript, representing its accuracy, completeness and non-redundant representation of a transcript that was present in the sequenced sample. The assembly score is calculated by using the contig scores, yielding a score that measures how complete the assembly is and how confident one can be with the assembly.
					\item \textbf{Uncovered bases percentage ($\downarrow$):} The proportion of bases that are not covered by any reads.
				\end{itemize}
		
			\item \textbf{\detonate} \citep{DETONATE:14}\\
				For some of its calculated metrics, \detonate estimates a `true' assembly. Briefly said, this would be an assembly constructed with prior knowledge of the position of each read.
				\begin{itemize}
					\item \textbf{K-mer compression score (KC score) ($\uparrow$):} 
					Reflects the similarity of an assembly compared to \detonate{}'s `true' assembly.					
					\item \textbf{RSEM EVAL ($\uparrow$):} A reference-free evaluation measure combining the compactness of an assembly and the support of the assembly through the set of reads it comes from.
					\item \textbf{Nucleotide/Contig F1 ($\uparrow$):} The F1 score describes the recovery of all nucleotides/contigs contained in the `true' assembly with a identity bigger than 90~\%.
				\end{itemize}

			\item \textbf{\busco} \citep{busco:15, busco:18}\\
			\busco scans an assembly in regards to detecting benchmarked universal single-copy orthologs (BUSCOs) from their OrthoDB. The database contains genes that are present as single-copy orthologs in at least 90~\% of the selected species.
			HMMER \citep{hmmer:11} detects genes in an assembly that match to the BUSCOs in their database. The identified BUSCO is considered complete if the sequence length of the match lies in the 95~\% expectation of the mean length of the specific BUSCO group.
				\begin{itemize}
					\item \textbf{Complete and single-copy BUSCOs ($\uparrow$):}
						The subset of complete BUSCOs that are present only once.
					\item \textbf{Complete and duplicated BUSCOs ($\downarrow$):}
						The subset of complete BUSCOs that are present multiple times.
					\item \textbf{Fragmented BUSCOs ($\downarrow$):}
						Identified BUSCOs, which are not in the expected range of length to represent a complete BUSCO. These indicate incomplete transcripts in case of a transcriptome.
					\item \textbf{Missing BUSCOs ($\downarrow$):}
						Unidentified or low-scoring BUSCOs.	For transcriptomes, this means that the orthologous genes are missing.
				\end{itemize}

			\item \textbf{\trinity and \salmon} \citep{Trinity:11, salmon:17}

				\begin{itemize}
					\item \textbf{Ex90N50 ($\uparrow$):}
					As explained in Section~\ref{ssec:evaluation}, the Ex90N50 value describes the N50 value based on the 90~\% of the highest expressed transcripts  from the total normalized expression data in the assembly.
				\end{itemize}

			\item \textbf{\hisat} \citep{hisat2:15}
				\begin{itemize}
					\item \textbf{Remapping rate ($\uparrow$):} The proportion of mapped reads divided by the number of nucleotides in the assembly.
				\end{itemize}
		
		\end{itemize}
	
	
	The heatmaps contain [0,1]-normalized values of the described metrics. The normalization takes into account whether a large or small value for the metric is considered good, thus in the heatmaps, a value of one always represents the best value.
	The complete metrics from all evaluation programs are accessible in the \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/assembly_eval}{supplemental data} (See Section~\ref{appendix:supplements}).

		
	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%% C. ELEGANS %%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

	\newpage
    Figure~\ref{img:cel_pe} lists the $[0,1]$-normalized assembly evaluation scores for the paired-end \celegans dataset (SRR5456164). The assembler \spades achieves the best overall score of 12.39. Concatenating all three assemblies from \spades, \soap and \trinity leads to a score of 9.13. The worst score of 6.00 takes \grouper, regardless of the choice of parameters. Considering only clustering tools, \cdhit (c=0.9) yields the highest sum score (12.32). The self-implemented algorithm \karma achieves a score of 9.49 and 6.92 (Parameters from Section~\ref{ssec:parameter}).\\
	
	\begin{figure}[H]
		\hspace{-13pt}
		\def\svgwidth{1.1\textwidth}
		\input{images/03_results/heatmap_cel_SRR5456164.pdf_tex}
		\caption[Normalized assembly evaluation metrics (\celegans, PE, SRR5456164).]{$[0,1]$-normalized assembly evaluation metrics for the paired-end \celegans dataset (SRR5456164). A score of 1 represents the best score. The last row summarizes all other metrics into a comparative score. `Combined' is the concatenated version from all three assemblers. The number in \cdhit represents the percentage of the chosen identity threshold. \grouper/\grouper{}*: \grouper with parameters \texttt{orphan} and \texttt{mincut} disabled/enabled. \karma: Parameters according to Section~\ref{sssec:karma}. \karma{}*: Parameters chosen in Section~\ref{ssec:parameter}. }
		\label{img:cel_pe}
	\end{figure}
	\newpage

	The [0, 1]-normalized metrics for the single-end \celegans dataset (ERR2886543) are shown in the heatmap in Figure~\ref{img:cel_se}.  From the used three assemblers, \spades gets the highest score of 11.26. The union of all three assemblies yields a score of 7.36. The best overall score (11.54) achieves \cdhit (c=0.9), which also makes it the clustering tool with the highest score. \karma scores a 8.22 with parameters from Section~\ref{ssec:parameter} and \karma{}* gets a score of 5.98.
	Finally, \grouper scores the lowest with a sum score of 4.41. This score is achieved regardless of whether different parameters are used.\\
	

	\begin{figure}[H]
		\hspace{-13pt}
		\def\svgwidth{1.1\textwidth}
		\input{images/03_results/heatmap_cel_ERR2886543.pdf_tex}
		\caption[Normalized assembly evaluation metrics (\celegans, SE, ERR2886543).]{$[0,1]$-normalized assembly evaluation metrics for the single-end \celegans dataset (ERR2886543). A score of 1 represents the best score. The last row summarizes all other metrics into a comparative score. `Combined' is the concatenated version from all three assemblers. The number in \cdhit represents the percentage of the chosen identity threshold. \grouper/\grouper{}*: \grouper with parameters \texttt{orphan} and \texttt{mincut} disabled/enabled. \karma: Parameters according to Section~\ref{sssec:karma}. \karma{}*: Parameters chosen in Section~\ref{ssec:parameter}.}
		\label{img:cel_se}
	\end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%% E. COLI %%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
	\newpage
	Figure~\ref{img:eco_pe} lists the $[0,1]$-normalized assembly evaluation scores for the paired-end \ecoli dataset (ERR779269). \soap yields the best overall score of 13.24. The other assemblers \spades (9.61) and \trinity (11.25) have lower scores. The concatenated assembly gets a score of 8.87. From all clustering methods, \cdhit (c=0.9) has the highest sum score of 10.30. \grouper gets the lowest overall score of 6.20. With the initial parameters (Section~\ref{sssec:karma}) \karma achieves score of 9.29 and a score of 6.11 with the parameters from Section~\ref{ssec:parameter} (\karma{}*).\\
		
	\begin{figure}[H]
		\hspace{-13pt}
		\def\svgwidth{1.1\textwidth}
		\input{images/03_results/heatmap_eco_ERR779269.pdf_tex}
		\caption[Normalized assembly evaluation metrics (\ecoli, PE, ERR779269).]{$[0,1]$-normalized assembly evaluation metrics for the paired-end \ecoli dataset (ERR779269). A score of 1 represents the best score. The last row summarizes all other metrics into a comparative score. `Combined' is the concatenated version from all three assemblers. The number in \cdhit represents the percentage of the chosen identity threshold. \grouper/\grouper{}*: \grouper with parameters \texttt{orphan} and \texttt{mincut} disabled/enabled. \karma: Parameters according to Section~\ref{sssec:karma}. \karma{}*: Parameters chosen in Section~\ref{ssec:parameter}.}
		\label{img:eco_pe}
	\end{figure}


	\newpage
    The heatmap in Figure~\ref{img:eco_se} shows the $[0,1]$-normalized assembly evaluation metrics for the single-end \ecoli dataset (SRR4255368). \cdhit (c=0.9) has the highest overall score of 10.80, which also makes it the highest-scoring clustering tool. The lowest score has \grouper (5.08). \karma gets a score of 7.08  and \karma{}* obtains a score of 5.23.
	Looking at the assemblers, \soap achieves the highest score (10.74) besides \spades (9.48) and \trinity (8.64). The concatenation of all three assemblers yields a score of 7.55.

	\begin{figure}[H]
		\hspace{-13pt}
		\def\svgwidth{1.1\textwidth}
		\input{images/03_results/heatmap_eco_SRR4255368.pdf_tex}
		\caption[Normalized assembly evaluation metrics (\ecoli, SE, SRR4255368).]{$[0,1]$-normalized assembly evaluation metrics for the single-end \ecoli dataset (SRR4255368). A score of 1 represents the best score. The last row summarizes all other metrics into a comparative score. `Combined' is the concatenated version from all three assemblers. The number in \cdhit represents the percentage of the chosen identity threshold. \grouper/\grouper{}*: \grouper with parameters \texttt{orphan} and \texttt{mincut} disabled/enabled. \karma: Parameters according to Section~\ref{sssec:karma}. \karma{}*: Parameters chosen in Section~\ref{ssec:parameter}.}
		\label{img:eco_se}
	\end{figure}

	\newpage
    For the artificial paired-end \celegans dataset, the [0,1]-normalized assembly evaluation metrics are shown in Figure~\ref{img:cel_flux}. Considering only assemblers, \trinity achieves the highest score (12.65) compared to \soap (11.86) and \spades (12.49), the concatenation of all three yields a score of 8.24.
	However, \cdhit (c=0.9) obtains the best overall score of 12.63. Both \grouper runs take the lowest score of 6.28. \karma gets a score of 9.20 and with alternative parameters (\karma{}*), the score is 6.54.

	\begin{figure}[H]
		\hspace{-13pt}
		\def\svgwidth{1.1\textwidth}
		\input{images/03_results/heatmap_cel_flux.pdf_tex}
		\caption[Normalized assembly evaluation metrics (\celegans, PE, CEL\_FLUX).]{$[0,1]$-normalized assembly evaluation metrics for the artificial paired-end \celegans dataset (CEL\_FLUX). A score of 1 represents the best score. The last row summarizes all other metrics into a comparative score. `Combined' is the concatenated version from all three assemblers. The number in \cdhit represents the percentage of the chosen identity threshold. \grouper/\grouper{}*: \grouper with parameters \texttt{orphan} and \texttt{mincut} disabled/enabled. \karma: Parameters according to Section~\ref{sssec:karma}. \karma{}*: Parameters chosen in Section~\ref{ssec:parameter}.}
		\label{img:cel_flux}
	\end{figure}


%%%%%%%%%%%%%%%%%%
%%% DISCUSSION %%%
%%%%%%%%%%%%%%%%%%
\newpage
\section{Discussion}
	The evaluation metrics from the previous section provide an interesting insight into the world of clustering \textit{de novo} transcriptome assemblies.
	While the self-implemented method \karma doesn't perform too well overall, it reveals an in-depth understanding of the underlying algorithm. Furthermore, the comparison of several state-of-the-art clustering methods shows significant differences between single-end and paired-end RNA-Seq data.

	\subsection{\texttt{cd-hit-est} consistently produces the best clusterings}
		\label{ssec:cdhit_is_best}
		%% CDHIT
        Throughout all examined datasets, \cdhit with a sequence identity of 90~\% outperforms the other clustering tools and yields the best results. \cdhit also manages to surpass the scores of the assemblers in two of the five datasets, thus improving the quality of the assembly based on the given evaluation metrics. Interestingly, those are both single-end datasets (ERR2886543 and SRR4255368), while for the paired-end datasets, either \spades, \soap or \trinity produce the best overall assembly.
		One of the most significant flaws while creating assemblies is the possibility of misassemblies \citep{transcriptome_misassemblies:11}. However, paired-end data possess additional information about the relative location of two paired reads.
		The utilization of this information reduces the number of misassemblies drastically, thus improving the assembly in general \citep{misassembly:15}.    
		Assemblers with an active development such as \spades \citep{rnaSPAdes:18} and \trinity \citep{Trinity:11} also include mechanisms to avoid misassemblies and detect alternatively spliced isoforms, leading to better assembly quality.
		
		Furthermore, \cdhit with a sequence identity of 100~\% still produces well-clustered assemblies. Usually, the size of the assembly with a 100~\% sequence identity is larger because the algorithm is more restrictive, resulting in more sequences, which leads to an overall worse score because of more redundancy.
	
	\subsection{Large datasets may be disadvantageous for \texttt{Grouper}}
		\label{ssec:discussion:grouper}
		%% GROUPER
		Although particularly designed for the clustering of \textit{de novo} transcriptome assemblies, \grouper consistently scores the worst sum score for all datasets.
		Nevertheless, the tool gets comparatively good scores for the following evaluation metrics: \textit{Remapping rate}, \textit{BUSCOs (F)}, \textit{BUSCOs (CD)}, \textit{uncovered bases} and \textit{misassemblies}.
		Those metrics are affected by the size of the \textit{de novo} transcriptome assembly in different ways.
		
		The two \busco scores (F and CD) and \textit{misassemblies} metrics are pure quantification measurements. Furthermore, they have the property that a smaller value represents a better score.
		Naturally, if the transcriptome assembly has a smaller size, the chance of, e.g., a misassembly being present, is inevitably smaller. The same principle applies to \textit{fragmented} and \textit{complete and duplicated BUSCOs}. 
		Consequently, \textit{missing} and \textit{complete and single BUSCOs} always have the lowest score. For example, the clustered assembly from \grouper in the single-end \celegans dataset (ERR2886543) contains only three contigs, while the \textit{Nematoda} dataset from \busco consists of 987 \busco groups. With such a difference, it comes to no surprise that those two \busco scores (M and CS) have consistently bad scores of zero.
		
		Even though the metric \textit{uncovered bases} and \textit{remapping rate} consider the proportion of uncovered bases and mapped reads, the scores might be misleading, in particular, for small-sized transcriptome assemblies. Even if an assembly has a hypothetical mapping rate of 100~\%, this doesn't result in a proper assembly if there is only one sequence.    
		In consequence, considering the size of the clustered assemblies from \grouper (Figures~\ref{img:barchart_flux}, \ref{img:barcharts:cel}, \ref{img:barcharts:ecos}) the evaluation results are rather unsurprising.
		
		Additionally, it seems suspicious that both runs with different parameters for \texttt{orphan} and \texttt{mincut} produce the same results. The investigation of the clustering pipeline eliminates an error due to wrong parameter settings. Another reason could be that changing the parameters doesn't have that much of an effect on these datasets.
		
		The clusterings from \grouper always contain the longest sequences. However, the reason for this behavior lies in the implementation of the clustering pipeline. Since \grouper doesn't provide an option of selecting representative sequences for its clusters, the longest sequence is chosen.
		Anyway, the amount of sequences gives also information about the number of produced clusters from \grouper (2--52). The reason for the low amount of groups compared to other clustering methods may be a combination of their graph-based implementation and the huge size of the input assemblies.
		With the increase of input sequences, the graph also grows bigger, allowing for more connections between the vertices of the graph. Additionally, as shown in Table~\ref{table:compare} their weighting function (Equation~\ref{eq:grouper_distance}) could complicate the clustering process with \mcl. Higher edge weights result in a better stochastic flow between vertices and if \mcl is not adjusted through its parameters, this may lead to fewer clusters.
	
	\subsection{Uneven sequence length distribution can be a challenge for \texttt{MeShClust}}
		%%MeShClust
		Overall, \mclust and \mclusttwo have average evaluation scores for their clustered assemblies (5.05--10.12) compared to \cdhit (8.35--12.63), which scores the best. This difference in clustering quality results could originate from the implementation of the \mclust algorithm. Unlike \cdhit, which compares sequences through actual sequence similarities, the authors of the tools used alignment-free measurements \citep{meshclust:18}. Combined with the selection of the shortest sequence for initial clusters, this could lead to a more unprecise clustering process, thus worse scores for their assembly.
	
	    The concatenated assemblies from the paired-end \celegans and single-end \ecoli dataset have the lowest median sequence length (SRR5456164: 240~nt, SRR4255368: 141~nt) and shortest sequence (SRR5456164: $\sim$6,000~nt, SRR4255368: $\sim$5,000~nt). All other datasets have a median sequence length above 285~nt and a maximum sequence length up to $\sim$120,000~nt.
		\mclusttwo was designed explicitly for longer sequences with lower similarity \citep{meshclust2:18}. Against the expectations, \mclusttwo achieves higher evaluation scores than \mclust for datasets with shorter maximum sequence lengths and smaller median sequence lengths.
		For the paired-end \celegans dataset, \mclusttwo gets a score of 10.12 and \mclust receives a score of 8.91 (Figure~\ref{img:cel_pe}). \mclusttwo scores an 8.53 and \mclust 8.19 on the single-end \ecoli dataset (Figure~\ref{img:eco_se}).
		A reason for this behavior could be, among other things, the uneven distribution of longer and shorter sequences with a majority of short sequences that neither \mclust and \mclusttwo can handle.
		The results indicate that \mclust and \mclusttwo might not be suitable for \textit{de novo} transcriptome clustering.
	
	\subsection{\texttt{Linclust}'s time-efficient algorithm might reduce clustering quality}
	    Looking at the runtimes of the clustering tools, one has to keep in mind that the time was only measured once per program and assembly. Even though this makes the results less reliable, it still gives a good relative impression of the time of calculations.
		Additionally, during the master's thesis, there were also latency problems on the used servers, which may explain some fluctuations of the runtimes.
		For example, in the single-end \celegans dataset (ERR2886543), \cdhit (c=0.9) takes about 12~hours to complete the clustering process. For all other datasets, the runtimes are way lower ($\sim$5~minutes up to $\sim$5~hours). Also, \cdhit (c=1) finishes the clustering process after $\sim$3~hours at the latest. This leads to the assumption that \cdhit (c=1) probably has a generally lower runtime. Still, the latency of the system may be the reason for a longer runtime for the single-end \celegans dataset.    
		For a reliable comparison, one should make sure to eliminate interfering factors beforehand and calculate the mean times from at least three distinct runs.
		
		However, with this information in mind, the runtime results (Table~\ref{table:runtimes}) are as expected. \linclust, which was specifically developed for time-efficient clustering, performs by far the fastest clusterings, regardless of the number of sequences in the concatenated assembly.
		Unfortunately, the fast calculation due to reduced sequence alignments comes with its costs.
		The clustering results usually average around a total sum score between 10--11 and are thus worse than the \cdhit clustering with 90~\% sequence identity.
		Only in rare cases, \linclust can achieve a better score than a single assembler. For example, in Figure~\ref{img:eco_se} \linclust gets a 9.96 whereas \spades only gets 9.45. Similar to \cdhit, the clusterings tend to have a high \textit{database coverage} and few \textit{missing BUSCOs}. This is most likely because the clustered assemblies from \linclust contain comparatively more sequences than those from other tools (Figure~\ref{img:barchart_flux}, \ref{img:barcharts:cel}, \ref{img:barcharts:ecos}).
		
	\subsection{Clustering with \texttt{karma} yields too few transcripts overall}
	\subsubsection{K-mer based clustering is not suitable for transcript clustering}
	\label{ssec:discussion:karma}
	While k-mer based clustering can work for metagenomic binning \citep{binning:16} or 16S rRNA clustering \citep{16SrRNA:13}, in this case, it seems that it gives rather disenchanting results for clustering transcripts.

	Initially, the method seems to be working in some cases (Section~\ref{ssec:graphs}, Case~2), where two different isoforms of the same gene share a k-mer based cluster.
	However, most of the initial k-mer based clusters show a mix of many different genes and isoforms (Section~\ref{ssec:graphs}, Case~1 and 3).
    The functions of the different genes in a cluster seem to be completely random based on research listed in the UniProt database \citep{uniprot:18}.
	For example, in the first case, the isoform F27D4.5.1 (\textit{bckd-1b}) is coding for a protein that positively regulates the larval development of \celegans \citep{F27:16}.
	Contrariliy, while Y37E3.15a.1 (\textit{npp-1}) is coding for a nuclear pore protein \citep{Y37:03}, T03F1.1.2 (\textit{uba-5}) plays an essential role in the pathway responsible for environmental stress factors such as heavy metals \citep{T03:13}. This discrepancy of functions applies to both case 1 and case 3.
	Luckily, if the contigs don't share reads (Case~1), the cluster is cleaned up through coverage information. However, as seen in the second case, a cluster stays mixed, if two or more sequences for each gene/isoform are in the same group. Therefore, the \hdbscan produces low-quality initial clusters.
	A possible reason could be a poor choice of parameters that may be addressed in future work for \karma. Likewise, the normalization of k-mer profiles based on the sequence length could be problematic. Hence sequences of significantly different lengths are falsely grouped.
	
	\subsubsection{New weighting function is not beneficial for \texttt{MCL} clustering}
	In its current implementation, \karma seems to perform a quite restrictive clustering, which results in an overall small-sized clustered assembly.
	When taking a closer look at the clusters built by \karma, it appears that there are a few clusters that contain more than 1,000 sequences. The problem with massive clusters is that the \mcl clustering usually only selects one representative isoform. It seems that either the parameters for \mcl are not suitable for those large clusters or the weights, similar to \grouper, are too high so that no subclusters can be formed.
	The newly implemented weighting function for \karma (Equation~\ref{eq:distance}) doesn't seem to improve this behavior as initially thought.
	
	As seen in all heatmaps (Figure~\ref{img:cel_pe}--\ref{img:cel_flux}), the alternative selection of parameters for \karma does not get better results as expected. It decreases the size of the clustered assembly and yields worse scores than the run with initial parameters. Yet, this fits with the previous statement regarding the size of the clusters. The \karma{}* assemblies usually have fewer larger clusters where \mcl is not dividing these into subclusters to select multiple representative sequences. This can be seen in the \texttt{clstr}-files in the \href{https://github.com/lmfaber/master_thesis/blob/master/supplemental_data/clusterings/clusterings.txt}{supplemental data} (Section~\ref{appendix:supplements}). 
	This leads to the assumption that for the current implementation of \karma, more k-mer based clusters would result in a better-clustered assembly.
	
	In a similar manner to \grouper, the problems mentioned above are the reason for a comparatively low amount of sequences in the clustered assembly (Figure~\ref{img:barchart_flux}, \ref{img:barcharts:cel}, \ref{img:barcharts:ecos}). Hence, the small assembly from \karma scores also very well for the evaluation metrics, where \grouper has high scores as well (See Section~\ref{ssec:discussion:grouper}).
	
	In terms of runtime, the initial number of k-mer based clusters seems to have a significant effect on \karma. 
	For example, in the simulated dataset, \hdbscan produces 2,604 clusters for the initial run (\karma) and 181 clusters with altered parameters (\karma{}*, Table~\ref{table:parameter}). The time for execution is approximately 23 minutes higher with more initial clusters (Table~\ref{table:runtimes}). The increased runtime could originate from the underlying non-optimized library for graph representation. For each existing graph, there are multiple steps to perform, including \mcl clustering, which will increase the time of execution.
	
	\subsection{Clustering multiple \textit{de novo} transcriptome assemblies is challenging}
	Even though \karma doesn't perform overwhelmingly good, this doesn't make its fundamental concept pointless.
	The idea of clustering multiple \textit{de novo} transcriptome assemblies is appealing at first glance. It seems like a simple task of combination and clustering redundancy to improve the resulting transcriptome assembly. In 2018, \citeauthor{OysterRiverProtocol:18} had a similar idea which resulted in the \orp \citep{OysterRiverProtocol:18}.
	
	However, the \orp, which was also explicitly designed for the same reason as \karma,  struggles to achieve better scores than the assemblers \soap, \spades and \trinity. 
	For example, the tool is not able to produce a better assembly than a single assembler does for the paired-end \ecoli dataset (Figure~\ref{img:eco_pe}). For the other paired-end \celegans datasets, the \orp is only able to achieve a higher score than \soap. 
	Still, multiple assemblers have the advantage of producing different sets of transcripts, potentially reducing the number of missing genes and isoforms (Figure~\ref{img:difference}).
	There may be a few reasons that the \orp still gets scores close to \cdhit. 
	
	
	Firstly, the \orp has its own assembly and preprocessing steps, which may improve the reads even further, compared to the outlined preprocessing steps in Section~\ref{ssec:assemblies}, which could lead to better assemblies from the beginning.
	Secondly, the sequence similarities are calculated through \orthofinder \citep{OrthoFinder:15}, which performs an all-vs-all \blast \citep{blast:90} query.
	Since \blast as well as \cdhit and \linclust works with sequence alignments, this could explain why the clustering process works comparatively well.
	
	Furthermore, \citeauthor{OysterRiverProtocol:18} uses the evaluation tool \transrate to optimize the results by choosing only the best contigs from the clusters based on \transrate \citep{OysterRiverProtocol:18}.
	For the \celegans datasets, the \orp produces its best scores (Figure~\ref{img:cel_pe}, \ref{img:cel_flux}). Noticeably, the size of the clustered assembly is approximately the same as the \cdhit assembly (Figure~\ref{img:barchart_flux}, \ref{img:barcharts:cel}) suggesting that the size of the assembly is somehow relevant for the evaluation scores.
	The self-created problem of redundancy seems to be a tougher challenge than initially thought.
	
	\subsection{Evaluation metrics do not necessarily represent a good assembly}
	    As already seen for the assemblies from \karma and \grouper, some metrics get the highest score, among other tools, although the assembly contains far too few contigs.
		If taken out of context, these metrics could lead to false assumptions. Hypothetically considering only the \textit{duplication ratio}, \textit{misassemblies}, percentage of \textit{uncovered bases}, \textit{complete and duplicated BUSCOs} and \textit{fragmented BUSCOs}, \grouper would have scored the best overall summed score among all assemblers and clustering tools.
		Therefore, a broadly and carefully selected repertoire is advised to balance out possible biased metrics.
	
		Furthermore, the evaluation of a single \textit{de novo} transcriptome assembly by itself might be misleading or could lead to wrong conclusions.
		Depending on the condition of an organism, cells may have a reduced set of expressed genes.
		For example, the paired-end \ecoli dataset (ERR779269), which was part of a study to investigate the pathogenicity of ArcA (aerobic respiratory control) \citep{arca_study:15}, has significantly less assembled transcripts than the single-end \ecoli dataset (Figure~\ref{img:barcharts:ecos}).
		ArcA represses a wide variety of aerobic enzymes under anaerobic conditions \citep{arca_function:88}.
		Hence, the chosen sample from the study might be the control group, where ArcA is fully functional. Thus the amount of expressed genes is low.
		It would be critical to state that a single \textit{de novo} transcriptome assembly is bad because of some metrics, without respecting the conditions of the sample. This is especially important to consider for quantitative metrics with a reference, such as \textit{BUSCOs}.
		However, for comparative analyses, as in this master's thesis or for a comprehensive study on different assemblers \citep{hoelzer:19}, such metrics provide an excellent way to measure characteristic differences.

	\subsection{K-mer size may affect the assembly quality of different species}
	    Comparing the performance of the assemblers throughout the different datasets, it appears that \soap outperforms \spades and \trinity for the \ecoli datasets and vice versa (Figure~\ref{img:cel_pe}--\ref{img:cel_flux}).
		In this study, \soap uses significantly larger k-mer sizes than the other assemblers (See Section~\ref{ssec:assemblies}), which could be one reason for the better results.
		
		As a prokaryote, \ecoli doesn't perform alternative splicing, contrarily to \celegans \citep{celegans_splicing:17}. Hence, each gene has only one isoform.
		As \citeauthor{optimization:10} suggest in their study, different k-mer sizes affect the profile of a transcriptome assembly \citep{optimization:10}.
		While shorter k-mer lengths will benefit the transcript diversity, which leads to more and fragmented transcripts, longer k-mer sizes allow for higher contiguity but with lower transcript diversity \citep{optimization:10}.
		Since \celegans likely has a higher transcript diversity because of alternative splicing, \soap may score worse for those datasets due to large k-mer sizes. In return, this favors the assemblies from \soap for the \ecoli datasets.
		
		Another reason for this could be the different implementations of the assemblers, leading to beneficial assemblies for \soap. In their study, \citeauthor{Rana:16} state that a distinct assembler has a higher impact on the assembly than k-mer sizes \citep{Rana:16}.
	
	\subsection{Future work leaves room for improvements}
    Contrarily to \karma, the \orp is limited to paired-end data only.
	Hence, \karma is still a respectful competitor to the \orp, because as described in Section~\ref{ssec:cdhit_is_best}, the most significant improvements through clustering were achieved on single-end datasets. Now, one might argue that the vast majority of new RNA-Seq data sets are produced using paired-end protocols. However, single-molecule real-time sequencing approaches such as provided by PacBio \citep{smrt:pacbio:09} or Oxford Nanopore \citep{smrt:ont:16} are more frequently used to sequence transcriptomes \citep{smrt:17}. Here, much longer reads are achieved, however, without any paired information.
	As for the future, \karma could also be used in a modified way to enhance Nanopore RNA-Seq data. 
	A basic idea could be a hybrid concept that complements the longer reads with short-read information from Illumina. The long reads could be initially k-mer clustered, while the quasi-mapping of the short reads might help to resolve isoforms. Such hybrid sequencing methods have been recently used for a \textit{de novo} transcriptome assembly and annotation, which showed an increased diversity of isoforms \citep{idp:18}.    
	
	Furthermore, a lot of time of this master's thesis was spent evaluating a broad spectrum of clustering methods on \textit{de novo} transcriptome assemblies. Thus the time for implementing the algorithm was limited.
	However, there are a few options and ideas that may improve the results of \karma.
	As already mentioned, the biggest drawback for \karma seems to be the size of the assembly.
	To address this issue, one could choose different approaches to increase the size of the clustered assembly.
	
	The main issue responsible for a small-sized assembly is the k-mer based clusters. On the one hand, more parameter tests could be performed, with regards to the number of clusters built or evaluation metrics from Section~\ref{ssec:comparison}. On the other hand, the k-mer based clustering with \umap and \hdbscan could be swapped against different clustering methods that may work better. Recent studies performed gene expression clustering using self-organizing maps \citep{gene_clustering:19} and multivariate Gaussian mixture models \citep{gene_clustering:16} that may be suitable for \karma as well.
	
	Again, the \mcl clustering seems to work for small clusters (Figure~\ref{img:cluster455a}) but fails for huge clusters (Section~\ref{ssec:discussion:karma}). Maybe the inflation parameter for \mcl could be increased to get a finer clustering result and consequently produce more sequences.
	
	Another potential improvement is possible for the cluster redefinition process of \karma (Figure~\ref{img:karma_workflow}C). Up to now, the k-mer based clusters, are iteratively combined with the large `unlabeled' group to remove or add sequences from those clusters. 
	Since a contig can also share reads with several other contigs, it might be better to first assign the 'unlabeled' contigs to all k-mer based groups and see where it fits best. A contig would then be assigned only to the cluster in which it has the highest number of connections or weight of edges.
	\newpage
	\section{Conclusion}
        In this master's thesis, the aim was to combine multiple \textit{de novo} transcriptome assemblies, concatenate them and produce a clustering that will outperform the assemblies from single assemblers.
		Given the facts from the discussion, it seems sufficient to rely on a single assembler rather than combining multiple assemblers for the most use cases. 
		However, the assembly might be slightly less complete compared to a clustered assembly.
		Eventually, the preprocessing steps, assembler choice and suitable k-mer size should be carefully considered.
		Furthermore, for RNA-Seq experiments where only single-end reads are available, it can be advantageous to perform multiple assemblies and to cluster them with \cdhit with a 90~\% sequence identity for improved results.
		Even though \karma was not able to outperform other clustering methods, mainly due to the size of the resulting clustered assembly, it still has great potential. 
		Contrarily to the \orp, it is also able to cluster \textit{de novo} transcriptome assemblies utilizing the coverage information from single-end reads, which might become more important with the rise of SMRT sequencing technologies producing long single-end reads.
		With further improvements of the algorithm in the future, \karma may still be a viable candidate for clustering \textit{de novo} transcriptome assemblies.
			
	
	

%%%%%%%%%%%%%%%%%%
%%% Quellen %%%
%%%%%%%%%%%%%%%%%%
\newpage
\pagestyle{fancy}

\bibliographystyle{custom-unsrtnat}

% Uses template.bib. Multiple files: template1,template2,...
\bibliography{master_thesis,programs}


\newpage
\section{List of figures}

\listoffigures

\newpage

\section{List of tables}
\listoftables

\newpage
\section{Appendix}
\label{appendix}
\subsection{Pipelines}
\label{appendix:pipelines}
\begin{itemize}
	\item Assembly: \href{https://github.com/lmfaber/multi\_assembly}{https://github.com/lmfaber/multi\_assembly}
	\item Clustering: \href{https://github.com/lmfaber/clustering}{https://github.com/lmfaber/clustering}.
	\item Evaluation: \href{https://github.com/lmfaber/evaluation}{https://github.com/lmfaber/evaluation}
\end{itemize}
\subsection{\texttt{karma}}
\label{appendix:karma}
	\begin{itemize}
	\item GitHub: \href{https://github.com/lmfaber/karma}{https://github.com/lmfaber/karma}
	\item Anaconda Cloud: 	\href{https://anaconda.org/lmfaber/karma}{https://anaconda.org/lmfaber/karma}
\end{itemize}

\subsection{Supplemental data}
\label{appendix:supplements}
The sequence alignments and the unnormalized evaluation metrics are available as printed version in this chapter. Additionally, everything else can be accessed through the online supplemental data in the following GitHub repository:\\
\href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data}{https://github.com/lmfaber/master\_thesis/tree/master/supplemental\_data}\\
\textbf{Subfolders:}
\begin{itemize}
	\item \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/assemblies_for_eval}{/assemblies\_for\_eval}: Contains all assemblies from all datasets on which the clusterings were performed.
	\item \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/assembly_eval}{/assembly\_eval}: Contains all evaluation metrics (normalized and unnormalized) of all evaluated assemblies.
	\item \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/clusterings}{/clusterings}: Contains all output files that were generated by the clustering tools for all datasets.
	\item \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/flux_simulator}{/flux\_simulator}: Contains the parameter file for the \flux and the simulated reads.
	\item \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/graphs}{/graphs}: Contains all clustering graphs from \karma for the simulated \celegans dataset.
	\item \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/parameter\_evaluation}{/parameter\_evaluation}: Complements the information of Table~\ref{table:runtimes}. Contains the full list of results from all tested parameters for the simulated \celegans dataset.
	\item \href{https://github.com/lmfaber/master_thesis/tree/master/supplemental_data/runtime}{/runtime}: Contains the runtimes of all programs for all datasets.


\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{sidewaysfigure}
	\centering
	\def\svgwidth{\textwidth}
	\input{images/03_results/alignments/F27D4.pdf_tex}
	\caption[Sequence alignment of the transcripts from Figure~\ref{img:cluster28}B.]{Sequence alignment of the transcripts from Figure~\ref{img:cluster28}B. The sequences from the final cluster 28 were aligned with \muscle \citep{muscle:04} and visualized with \jalview \citep{jalview:09}. Hyphens represent mismatches between sequences.}
	\label{img:aln:case1}
\end{sidewaysfigure}

\begin{sidewaysfigure}
	\centering
	\def\svgwidth{\textwidth}
	\input{images/03_results/alignments/C25A1.pdf_tex}
	\caption[Sequence alignment of the transcripts from Figure~\ref{img:cluster455a}.]{Sequence alignment of the transcripts from Figure~\ref{img:cluster455a}. The sequences from the final cluster 455 were aligned with \muscle \citep{muscle:04} and visualized with \jalview \citep{jalview:09}. Hyphens represent mismatches between sequences.}
	\label{img:aln:case2}
\end{sidewaysfigure}


\begin{sidewaysfigure}
	\def\svgwidth{\textwidth}
	\centering
	\input{images/03_results/alignments/Cluster660.pdf_tex}
	\caption[Sequence alignment of the transcripts from Figure~\ref{img:cluster660}.]{Sequence alignment of the transcripts from Figure~\ref{img:cluster660}. The sequences from the final cluster 660 were aligned with \muscle \citep{muscle:04} and visualized with \jalview \citep{jalview:09}. Hyphens represent mismatches between sequences.}
	\label{img:aln:case3}
\end{sidewaysfigure}



\begin{sidewaystable}
		\caption[Assembly evaluation metrics (\celegans, PE, SRR5456164).]{\footnotesize Assembly evaluation metrics for the paired-end \celegans dataset (SRR5456164). BUSCOs (CS): Complete and single BUSCOs, BUSCOs (CD): Complete and duplicated BUSCOs, BUSCOs (F): Fragmented BUSCOs, BUSCOs (M): Missing BUSCOs, ORF: Open reading frame}

		\label{table:cel_SRR5456164} 
		\begin{tiny}
	
		\resizebox{\linewidth}{!}{%
		\begin{tabular}{l*{7}{r}}
			\toprule
			& \spades & \soap & \trinity & Combined & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=1)\end{tabular} & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=0.9)\end{tabular} & \linclust \\
			\midrule
			Database coverage & 0.151 & 0.069 & 0.098 & 0.173 & 0.164 & 0.154 & 0.169 \\
			Duplication ratio & 1.05 & 1.101 & 1.038 & 1.949 & 1.365 & 1.07 & 1.554 \\
			95~\%-assembled isoforms & 417 & 90 & 283 & 482 & 475 & 434 & 379 \\
			Misassemblies & 688 & 15 & 248 & 951 & 904 & 782 & 851 \\
			Mean ORF percentage & 81.30865 & 92.09741 & 90.10208 & 86.02784 & 83.73223 & 81.88296 & 85.47737 \\
			Assembly score & 0.36624 & 0.10638 & 0.1889 & 0.13718 & 0.28287 & 0.35542 & 0.17099 \\
			Uncovered bases percentage & 0.06144 & 0.03603 & 0.02127 & 0.25763 & 0.1214 & 0.06866 & 0.20535 \\
			KC score & 0.950132 & 0.835138 & 0.912559 & 0.975307 & 0.977535 & 0.959043 & 0.96687 \\
			RSEM EVAL & -1770045340.73 & -3613516656.57 & -2632714766.87 & -1430506439.82 & -1423168410.06 & -1604350521.67 & -1579390663.72 \\
			Nucleotide F1 & 0.654158 & 0.567724 & 0.662377 & 0.432028 & 0.549393 & 0.649173 & 0.505907 \\
			Contig F1 & 0.0374303 & 0.0690062 & 0.0770611 & 0.0753873 & 0.0547396 & 0.0379768 & 0.0772868 \\
			BUSCOs (CS) & 284 & 116 & 228 & 90 & 176 & 288 & 238 \\
			BUSCOs (CD) & 19 & 29 & 23 & 221 & 135 & 19 & 63 \\
			BUSCOs (F) & 137 & 98 & 121 & 140 & 140 & 144 & 147 \\
			BUSCOs (M) & 542 & 739 & 610 & 531 & 531 & 531 & 534 \\
			Ex90N50 & 24895 & 11088 & 10579 & 33393 & 28380 & 24861 & 32160 \\
			Remapping rate & 0.0795 & 0.1571 & 0.1236 & 0.0419 & 0.0589 & 0.0769 & 0.05234 \\
			\midrule
			\midrule
			& \mclust & \mclusttwo & \grouper & \grouper{}* & \karma & \karma{}* & \begin{tabular}[c]{@{}l@{}}\prgm{Oyster River}\\\prgm{Protocol} \end{tabular} \\
			\midrule
			Database coverage & 0.08 & 0.163 & 0 & 0 & 0.044 & 0.019 & 0.135 \\
			Duplication ratio & 1.245 & 1.656 & 1 & 1 & 1.04 & 1.02 & 1.199 \\
			95~\%-assembled isoforms & 171 & 422 & 1 & 1 & 181 & 34 & 299 \\
			Misassemblies & 270 & 751 & 0 & 0 & 117 & 59 & 1083 \\
			Mean ORF percentage & 87.17259 & 86.42228 & 69.92872 & 69.92872 & 85.70663 & 87.05276 & 84.1247 \\
			Assembly score & 0.09723 & 0.14648 & 0.00617 & 0.00617 & 0.11471 & 0.02165 & 0.43475 \\
			Uncovered bases percentage & 0.11949 & 0.21675 & 0.01356 & 0.01356 & 0.03385 & 0.03957 & 0.06177 \\
			KC score & 0.544173 & 0.925971 & 0.0159385 & 0.0159385 & 0.566657 & 0.16227 & 0.917622 \\
			RSEM EVAL & -4665266225.96 & -1875165073.13 & -7881078430.36 & -7881078430.36 & -4644800060.3 & -7046835191.71 & -1749138759.43 \\
			Nucleotide F1 & 0.464802 & 0.483952 & 0.00565165 & 0.00565165 & 0.400357 & 0.193878 & 0.597937 \\
			Contig F1 & 0.0485081 & 0.0750382 & 4.89E-05 & 4.89E-05 & 0.0377662 & 0.0180084 & 0.0421688 \\
			BUSCOs (CS) & 115 & 152 & 1 & 1 & 137 & 31 & 247 \\
			BUSCOs (CD) & 47 & 144 & 0 & 0 & 8 & 1 & 25 \\
			BUSCOs (F) & 89 & 136 & 0 & 0 & 56 & 27 & 127 \\
			BUSCOs (M) & 731 & 550 & 981 & 981 & 781 & 923 & 583 \\
			Ex90N50 & 14827 & 31540 & 34 & 34 & 4557 & 2131 & 21464 \\
			Remapping rate & 0.0756 & 0.0494 & 0.4094 & 0.4094 & 0.1626 & 0.1195 & 0.0775 \\ \bottomrule
		\end{tabular} 
	}
\end{tiny}
\end{sidewaystable}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{sidewaystable}
	
	\caption[Assembly evaluation metrics (\celegans, SE, ERR2886543).]{\footnotesize Assembly evaluation metrics for the single-end \celegans dataset (ERR2886543). BUSCOs (CS): Complete and single BUSCOs, BUSCOs (CD): Complete and duplicated BUSCOs, BUSCOs (F): Fragmented BUSCOs, BUSCOs (M): Missing BUSCOs, ORF: Open reading frame}
	\label{table:cel_ERR2886543} 
	
	\begin{tiny}
		
		\resizebox{\linewidth}{!}{%
			\begin{tabular}{ l  *{7}{r} }
				\toprule
				& \spades & \soap & \trinity & Combined & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=1)\end{tabular} & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=0.9)\end{tabular} & \linclust \\
				\midrule
				Database coverage & 0.249 & 0.274 & 0.244 & 0.311 & 0.293 & 0.269 & 0.292 \\
				Duplication ratio & 1.026 & 1.1 & 1.027 & 2.599 & 1.401 & 1.027 & 1.288 \\
				95~\%-assembled isoforms & 3845 & 3864 & 4304 & 4901 & 4783 & 4478 & 4334 \\
				Misassemblies & 29 & 11 & 72 & 112 & 100 & 76 & 76 \\
				KC score & 0.929661 & 0.942305 & 0.929062 & 0.929203 & 0.949659 & 0.940393 & 0.944621 \\
				RSEM EVAL & -489761901.22 & -485577948.13 & -495633718.12 & -514513375.08 & -482131738.91 & -480112050.53 & -484019914.15 \\
				Nucleotide F1 & 0.773771 & 0.756324 & 0.774879 & 0.437381 & 0.657823 & 0.78824 & 0.683277 \\
				Contig F1 & 0.113996 & 0.109491 & 0.135287 & 0.0928126 & 0.117546 & 0.124116 & 0.107675 \\
				BUSCOs (CS) & 720 & 654 & 756 & 28 & 418 & 761 & 714 \\
				BUSCOs (CD) & 29 & 118 & 27 & 762 & 373 & 27 & 74 \\
				BUSCOs (F) & 51 & 51 & 48 & 44 & 44 & 45 & 44 \\
				BUSCOs (M) & 182 & 159 & 151 & 148 & 147 & 149 & 150 \\
				Ex90N50 & 12206 & 14730 & 7522 & 20003 & 18022 & 17253 & 19470 \\
				Remapping rate & 0.6211 & 0.5376 & 0.6216 & 0.2005 & 0.3899 & 0.5703 & 0.4246 \\
				\midrule
				\midrule
				& \mclust & \mclusttwo & \grouper & \grouper{}* & \karma & \karma{}* & \begin{tabular}[c]{@{}l@{}}~\\~ \end{tabular}\\
				\midrule
				Database coverage & 0.272 & 0.06 & 0.001 & 0.001 & 0.113 & 0.032 &  \\
				Duplication ratio & 1.775 & 1.266 & 1 & 1 & 1.035 & 1.014 &  \\
				95~\%-assembled isoforms & 4173 & 121 & 1 & 1 & 1938 & 589 &  \\
				Misassemblies & 76 & 6 & 0 & 0 & 23 & 4 &  \\
				KC score & 0.869096 & 0.113817 & 0.000958855 & 0.000958855 & 0.537434 & 0.155587 &  \\
				RSEM EVAL & -574208935.19 & -1431812964.55 & -1579133183.78 & -1579133183.78 & -948072484.18 & -1399343882.81 &  \\
				Nucleotide F1 & 0.556362 & 0.222673 & 0.00350515 & 0.00350515 & 0.459621 & 0.159376 &  \\
				Contig F1 & 0.0987958 & 0.00922742 & 5.89E-05 & 5.89E-05 & 0.0677556 & 0.0222713 &  \\
				BUSCOs (CS) & 219 & 11 & 0 & 0 & 372 & 127 &  \\
				BUSCOs (CD) & 546 & 1 & 0 & 0 & 15 & 3 &  \\
				BUSCOs (F) & 46 & 14 & 0 & 0 & 29 & 11 &  \\
				BUSCOs (M) & 171 & 956 & 982 & 982 & 566 & 841 &  \\
				Ex90N50 & 19023 & 11292 & 6277 & 6277 & 2707 & 358 &  \\
				Remapping rate & 0.3101 & 0.2768 & 0.2684 & 0.2684 & 0.7802 & 0.8119 & \\
				\bottomrule
				
			\end{tabular}
		}
		
	\end{tiny}
\end{sidewaystable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{sidewaystable}

		\caption[Assembly evaluation metrics (\ecoli, PE, ERR779269).]{\footnotesize Assembly evaluation metrics for the paired-end \ecoli dataset (ERR779269). BUSCOs (CS): Complete and single BUSCOs, BUSCOs (CD): Complete and duplicated BUSCOs, BUSCOs (F): Fragmented BUSCOs, BUSCOs (M): Missing BUSCOs, ORF: Open reading frame}

		\label{table:eco_ERR779269} 
		\begin{tiny}
		
		\resizebox{\linewidth}{!}{%
		
		\begin{tabular}{ l  *{7}{r} }
			\toprule
			& \spades & \soap & \trinity & Combined & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=1)\end{tabular} & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=0.9)\end{tabular} & \linclust \\
			\midrule
			Database coverage & 0.065 & 0.194 & 0.082 & 0.224 & 0.111 & 0.059 & 0.218 \\
			Duplication ratio & 1.161 & 1.177 & 1.277 & 1.825 & 1.621 & 1.128 & 1.485 \\
			95~\%-assembled isoforms & 130 & 357 & 158 & 459 & 224 & 117 & 444 \\
			Misassemblies & 233 & 146 & 157 & 536 & 414 & 234 & 408 \\
			Mean ORF percentage & 12.86926 & 28.65736 & 14.79746 & 17.48951 & 13.59771 & 11.93826 & 18.13838 \\
			Assembly score & 0.13693 & 0.22281 & 0.5385 & 0.07283 & 0.11412 & 0.13419 & 0.0897 \\
			Uncovered bases percentage & 0.14179 & 0.02989 & 0.08143 & 0.34989 & 0.29899 & 0.11163 & 0.2692 \\
			KC score & 0.34177 & 0.347566 & 0.342539 & 0.336395 & 0.340589 & 0.344052 & 0.340153 \\
			RSEM EVAL & -783567110.5 & -790600958.27 & -758163030.28 & -723526184.49 & -716761173.43 & -765690474.66 & -720900920.72 \\
			Nucleotide F1 & 0.429352 & 0.611536 & 0.49515 & 0.203084 & 0.263362 & 0.417534 & 0.26169 \\
			Contig F1 & 0.00105694 & 0.00136593 & 0.000363769 & 0.00133869 & 0.000883197 & 0.000530434 & 0.00148134 \\
			BUSCOs (CS) & 286 & 371 & 332 & 113 & 177 & 258 & 153 \\
			BUSCOs (CD) & 155 & 144 & 124 & 484 & 379 & 182 & 440 \\
			BUSCOs (F) & 20 & 10 & 11 & 0 & 8 & 13 & 3 \\
			BUSCOs (M) & 320 & 256 & 314 & 184 & 217 & 328 & 185 \\
			Ex90N50 & 61 & 222 & 327 & 246 & 254 & 601 & 230 \\
			Remapping rate & 0.0877 & 0.1447 & 0.1041 & 0.0358 & 0.0484 & 0.0857 & 0.0487 \\
			\midrule
			\midrule
			& \mclust & \mclusttwo & \grouper & \grouper{}* & \karma & \karma{}* & \begin{tabular}[c]{@{}l@{}}\prgm{Oyster River}\\\prgm{Protocol} \end{tabular} \\
			\midrule
			Database coverage & 0.216 & 0.029 & 0.001 & 0.001 & 0.04 & 0.016 & 0.219 \\
			Duplication ratio & 1.606 & 1.187 & 1 & 1 & 1.139 & 1.041 & 1.312 \\
			95~\%-assembled isoforms & 435 & 21 & 1 & 1 & 63 & 20 & 335 \\
			Misassemblies & 404 & 25 & 1 & 1 & 93 & 23 & 1586 \\
			Mean ORF percentage & 21.2563 & 46.24479 & 2.36694 & 2.36694 & 12.18414 & 15.7588 & 26.77923 \\
			Assembly score & 0.08534 & 0.01459 & 0.06134 & 0.06134 & 0.06614 & 0.00506 & 0.22179 \\
			Uncovered bases percentage & 0.25007 & 0.07262 & 0.00037 & 0.00037 & 0.06844 & 0.03047 & 0.17172 \\
			KC score & 0.34116 & 0.05506 & 0.0216994 & 0.0216994 & 0.288863 & 0.0424645 & 0.2901 \\
			RSEM EVAL & -723686090.15 & -3860650563.98 & -4279875760.58 & -4279875760.58 & -1790575524.2 & -3991884547.23 & -801951086.83 \\
			Nucleotide F1 & 0.284619 & 0.147295 & 0.0747459 & 0.0747459 & 0.44664 & 0.181951 & 0.38483 \\
			Contig F1 & 0.00124644 & 0.00067325 & 0 & 0 & 0.00113723 & 0 & 0.000572355 \\
			BUSCOs (CS) & 154 & 34 & 8 & 8 & 221 & 35 & 308 \\
			BUSCOs (CD) & 428 & 15 & 5 & 5 & 74 & 15 & 190 \\
			BUSCOs (F) & 4 & 22 & 0 & 0 & 13 & 7 & 44 \\
			BUSCOs (M) & 195 & 710 & 768 & 768 & 473 & 724 & 239 \\
			Ex90N50 & 228 & 120 & 113 & 113 & 62 & 72 & 92 \\
			Remapping rate & 0.0536 & 0.1304 & 0.2928 & 0.2928 & 0.1452 & 0.1675 & 0.0776 \\
			\bottomrule

		\end{tabular} 
	}
\end{tiny}
\end{sidewaystable}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{sidewaystable}

		\caption[Assembly evaluation metrics (\ecoli, SE, SRR4255368).]{\footnotesize Assembly evaluation metrics for the single-end \ecoli dataset (SRR4255368). BUSCOs (CS): Complete and single BUSCOs, BUSCOs (CD): Complete and duplicated BUSCOs, BUSCOs (F): Fragmented BUSCOs, BUSCOs (M): Missing BUSCOs, ORF: Open reading frame}

		\label{table:eco_SRR4255368} 
		
		\begin{tiny}
			
		\resizebox{\linewidth}{!}{%
		\begin{tabular}{ l  *{7}{r} }
			\toprule
			& \spades & \soap & \trinity & Combined & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=1)\end{tabular} & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=0.9)\end{tabular} & \linclust \\
			\midrule
			Database coverage & 0.271 & 0.406 & 0.197 & 0.418 & 0.41 & 0.404 & 0.413 \\
			Duplication ratio & 1.026 & 1.111 & 1.008 & 2.219 & 1.277 & 1.035 & 1.351 \\
			95~\%-assembled isoforms & 188 & 238 & 228 & 288 & 268 & 248 & 273 \\
			Misassemblies & 1 & 2 & 5 & 8 & 7 & 7 & 7 \\
			KC score & 0.798691 & 0.855741 & 0.769881 & 0.865486 & 0.868888 & 0.867401 & 0.861875 \\
			RSEM EVAL & -306072610.64 & -280456633.52 & -328451127.12 & -275469820.25 & -273036723.67 & -274948642.84 & -275714130.72 \\
			Nucleotide F1 & 0.500731 & 0.499008 & 0.435121 & 0.351697 & 0.476455 & 0.529708 & 0.459695 \\
			Contig F1 & 0.0186955 & 0.061932 & 0.0102523 & 0.0520025 & 0.0630086 & 0.0661045 & 0.0589524 \\
			BUSCOS (CS) & 107 & 111 & 133 & 24 & 95 & 141 & 108 \\
			BUSCOS (CD) & 0 & 25 & 0 & 124 & 50 & 0 & 32 \\
			BUSCOS (F) & 270 & 287 & 262 & 294 & 294 & 292 & 291 \\
			BUSCOS (M) & 404 & 358 & 386 & 339 & 342 & 348 & 350 \\
			Ex90N50 & 3933 & 7388 & 1193 & 9123 & 7884 & 7434 & 8410 \\
			Remapping rate & 0.0584 & 0.03761 & 0.0738 & 0.01843 & 0.0320 & 0.0404 & 0.0306 \\
			\midrule
			\midrule
		& \mclust & \mclusttwo & \grouper & \grouper{}* & \karma & \karma{}* & \begin{tabular}[c]{@{}l@{}}~\\~ \end{tabular} \\
			\midrule
			Database coverage & 0.393 & 0.404 & 0.001 & 0.001 & 0.139 & 0.036 &  \\
			Duplication ratio & 1.801 & 1.714 & 1 & 1 & 1.029 & 1.011 &  \\
			95~\%-assembled isoforms & 269 & 237 & 3 & 3 & 137 & 45 &  \\
			Misassemblies & 7 & 8 & 0 & 0 & 4 & 0 &  \\
			KC score & 0.77146 & 0.765025 & 0.0475044 & 0.0475044 & 0.508967 & 0.185939 &  \\
			RSEM EVAL & -321998360.25 & -322589311.48 & -784332546.24 & -784332546.24 & -457645275.72 & -694202626.05 &  \\
			Nucleotide F1 & 0.402484 & 0.40176 & 0.00742467 & 0.00742467 & 0.321919 & 0.0988829 &  \\
			Contig F1 & 0.0512347 & 0.0553151 & 0 & 0 & 0.0107127 & 0.00282716 &  \\
			BUSCOS (CS) & 48 & 64 & 9 & 9 & 82 & 30 &  \\
			BUSCOS (CD) & 79 & 46 & 0 & 0 & 5 & 0 &  \\
			BUSCOS (F) & 295 & 286 & 1 & 1 & 181 & 56 &  \\
			BUSCOS (M) & 359 & 385 & 771 & 771 & 513 & 695 &  \\
			Ex90N50 & 8253 & 8892 & 1076 & 1076 & 1308 & 351 &  \\
			Remapping rate & 0.02236 & 0.0228 & 0.2634 & 0.2634 & 0.0747 & 0.0922 & \\ \bottomrule

		\end{tabular} 
	}
\end{tiny}
\end{sidewaystable}

\begin{sidewaystable}
	\centering
	%TODO captions
	%TODO Highlight the best value
	
	
	\caption[Assembly evaluation metrics (\celegans, PE, CEL\_FLUX).]{\footnotesize Assembly evaluation metrics for the artificial paired-end \celegans dataset (CEL\_FLUX). BUSCOs (CS): Complete and single BUSCOs, BUSCOs (CD): Complete and duplicated BUSCOs, BUSCOs (F): Fragmented BUSCOs, BUSCOs (M): Missing BUSCOs, ORF: Open reading frame}
	\label{table:cel_flux} 
	\begin{tiny}
		\resizebox{\linewidth}{!}{%
			\begin{tabular}{ l  *{7}{r} }
				\toprule
				& \spades & \soap & \trinity & Combined & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=1)\end{tabular} & \begin{tabular}[c]{@{}l@{}}\cdhit\\ (c=0.9)\end{tabular} & \linclust \\
				\midrule
				Database coverage & 0.07 & 0.056 & 0.076 & 0.097 & 0.086 & 0.072 & 0.087 \\
				Duplication ratio & 1.041 & 1.037 & 1.141 & 2.237 & 1.4 & 1.083 & 1.529 \\
				95~\%-assembled isoforms & 1816 & 540 & 1255 & 2160 & 2083 & 1839 & 1648 \\
				Misassemblies & 31 & 0 & 6 & 37 & 36 & 29 & 27 \\
				Mean ORF percentage & 78.95958 & 89.51723 & 84.23147 & 83.64537 & 80.64075 & 79.58343 & 83.98252 \\
				Assembly score & 0.25561 & 0.06978 & 0.22252 & 0.0425 & 0.16848 & 0.24241 & 0.04352 \\
				Uncovered bases percentage & 0.02938 & 0.04726 & 0.06874 & 0.45727 & 0.20047 & 0.04366 & 0.34469 \\
				KC score& 0.874929 & 0.856403 & 0.85325 & 0.709287 & 0.830489 & 0.873406 & 0.810111 \\
				RSEM EVAL & -33440249 & -47944582.15 & -36491081.99 & -39794629.7 & -31751191.58 & -30412076.44 & -35984585.37 \\
				Nucleotide F1 & 0.822899 & 0.773512 & 0.769122 & 0.457153 & 0.668369 & 0.813667 & 0.625944 \\
				Contig F1 & 0.08026 & 0.0905651 & 0.110345 & 0.106274 & 0.0908302 & 0.0794115 & 0.112156 \\
				BUSCOs (CS) & 166 & 96 & 135 & 25 & 110 & 176 & 127 \\
				BUSCOs (CD) & 13 & 10 & 34 & 158 & 73 & 5 & 52 \\
				BUSCOs (F) & 30 & 51 & 38 & 28 & 28 & 29 & 31 \\
				BUSCOs (M) & 773 & 825 & 775 & 771 & 771 & 772 & 772 \\
				Ex90N50 & 2775 & 3803 & 3147 & 3770 & 3340 & 2844 & 3493 \\
				Remapping rate & 0.1935 & 0.2432 & 0.1644 & 0.0685 & 0.1212 & 0.1821 & 0.1103 \\
				\midrule
				\midrule
				& \mclust & \mclusttwo & \grouper & \grouper{}* & \karma & \karma{}* & \begin{tabular}[c]{@{}l@{}}\prgm{Oyster River}\\\prgm{Protocol} \end{tabular} \\
				\midrule
				Database coverage & 0.091 & 0.044 & 0 & 0 & 0.035 & 0.015 & 0.075 \\
				Duplication ratio & 1.835 & 1.391 & 2 & 2 & 1.105 & 1.108 & 1.176 \\
				95~\%-assembled isoforms & 1919 & 611 & 1 & 1 & 612 & 154 & 1569 \\
				Misassemblies & 34 & 2 & 0 & 0 & 3 & 1 & 40 \\
				Mean ORF percentage & 84.23501 & 88.77639 & 97.11379 & 97.11379 & 83.97072 & 88.33136 & 81.67814 \\
				Assembly score & 0.0428 & 0.01642 & 0.01929 & 0.01957 & 0.01925 & 0.00199 & 0.29506 \\
				\% bases uncovered & 0.39997 & 0.23236 & 0.00056 & 0.00016 & 0.09821 & 0.10377 & 0.09251 \\
				KC score & 0.768498 & 0.329479 & 0.023261 & 0.023261 & 0.545569 & 0.116105 & 0.856374 \\
				RSEM EVAL & -37692169.22 & -97870947.76 & -127943113.61 & -127943113.61 & -73650870.05 & -119216677.57 & -32710610.97 \\
				Nucleotide F1 & 0.545201 & 0.526054 & 0.0119664 & 0.0119664 & 0.546058 & 0.287783 & 0.751547 \\
				Contig F1 & 0.113653 & 0.0687602 & 0.000189843 & 0.000189843 & 0.0649272 & 0.0354412 & 0.0889001 \\
				BUSCOs (CS) & 46 & 27 & 0 & 0 & 65 & 24 & 140 \\
				BUSCOs (CD) & 135 & 7 & 1 & 1 & 11 & 0 & 30 \\
				BUSCOs (F) & 30 & 37 & 0 & 0 & 17 & 14 & 34 \\
				BUSCOs (M) & 771 & 911 & 981 & 981 & 889 & 944 & 778 \\
				Ex90N50 & 3603 & 3436 & 1514 & 1514 & 2068 & 1441 & 3336 \\
				Remapping rate & 0.0886 & 0.10479 & 0.3805 & 0.3805 & 0.2249 & 0.1383 & 0.1618\\
				\bottomrule
			\end{tabular} 
		}
	\end{tiny}
\end{sidewaystable}


\newpage
\pagestyle{empty}
\twocolumn
\section*{Declaration of authorship}
I declare that I have done this work independently and only using the sources and resources provided. There are no objections on the part of the author to make the present master thesis available for public use in the university archives.
\vspace*{3cm}

Jena, \today
\newpage
\section*{ }
Ich erkläre, dass ich die vorliegende Arbeit selbstständig und nur unter Verwendung der angegebenen Quellen und Hilfsmittel angefertigt habe. Seitens des Verfassers bestehen keine Einwände die vorliegende Masterarbeit für die öffentliche Benutzung im Universitätsarchiv zur Verfügung zu stellen.


% Unterschrift (handgeschrieben)

\end{document}